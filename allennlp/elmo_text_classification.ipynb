{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    testing=True,\n",
    "    seed=1,\n",
    "    batch_size=64,\n",
    "    lr=3e-4,\n",
    "    epochs=2,\n",
    "    hidden_sz=64,\n",
    "    max_seq_len=100, # necessary to limit memory usage\n",
    "    max_vocab_size=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.checks import ConfigurationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data\") / \"jigsaw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed manually to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114181630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
    "              \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
    "\n",
    "class JigsawDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[Token], id: str,\n",
    "                         labels: np.ndarray) -> Instance:\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        id_field = MetadataField(id)\n",
    "        fields[\"id\"] = id_field\n",
    "        \n",
    "        label_field = ArrayField(array=labels)\n",
    "        fields[\"label\"] = label_field\n",
    "\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                [Token(x) for x in self.tokenizer(row[\"comment_text\"])],\n",
    "                row[\"id\"], row[label_cols].values,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare token handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the spacy tokenizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "\n",
    "# the token indexer is responsible for mapping tokens to integers\n",
    "token_indexer = ELMoTokenCharactersIndexer()\n",
    "\n",
    "def tokenizer(x: str):\n",
    "    return [w.text for w in\n",
    "            SpacyWordSplitter(language='en_core_web_sm', \n",
    "                              pos_tags=False).split_words(x)[:config.max_seq_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = JigsawDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [00:01, 205.20it/s]\n",
      "251it [00:00, 319.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train.csv\", \"test_proced.csv\"])\n",
    "val_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<allennlp.data.instance.Instance at 0x1a2dc8f748>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dc74630>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dc4a2b0>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dbf1470>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dbe5860>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dbdbef0>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dbd69b0>,\n",
       " <allennlp.data.instance.Instance at 0x1a2dc8f0f0>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b95a358>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b9b80f0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [Explanation,\n",
       "  Why,\n",
       "  the,\n",
       "  edits,\n",
       "  made,\n",
       "  under,\n",
       "  my,\n",
       "  username,\n",
       "  Hardcore,\n",
       "  Metallica,\n",
       "  Fan,\n",
       "  were,\n",
       "  reverted,\n",
       "  ?,\n",
       "  They,\n",
       "  were,\n",
       "  n't,\n",
       "  vandalisms,\n",
       "  ,,\n",
       "  just,\n",
       "  closure,\n",
       "  on,\n",
       "  some,\n",
       "  GAs,\n",
       "  after,\n",
       "  I,\n",
       "  voted,\n",
       "  at,\n",
       "  New,\n",
       "  York,\n",
       "  Dolls,\n",
       "  FAC,\n",
       "  .,\n",
       "  And,\n",
       "  please,\n",
       "  do,\n",
       "  n't,\n",
       "  remove,\n",
       "  the,\n",
       "  template,\n",
       "  from,\n",
       "  the,\n",
       "  talk,\n",
       "  page,\n",
       "  since,\n",
       "  I,\n",
       "  'm,\n",
       "  retired,\n",
       "  now.89.205.38.27],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x1a2a760be0>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[0].fields[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to build the vocab: all that is handled by the token indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterator is responsible for batching the data and preparing it for input into the model. We'll use the BucketIterator that batches text sequences of smilar lengths together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=config.batch_size, \n",
    "                          sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the iterator how to numericalize the text data. We do this by passing the vocabulary to the iterator. This step is easy to forget so be careful! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': {'tokens': tensor([[[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  90, 102,  ..., 261, 261, 261],\n",
       "           [259, 117, 105,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  74, 260,  ..., 261, 261, 261],\n",
       "           [259,  71,  74,  ..., 261, 261, 261],\n",
       "           [259,  74,  85,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  71, 115,  ..., 261, 261, 261],\n",
       "           [259, 100, 109,  ..., 261, 261, 261],\n",
       "           [259,  74, 260,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[259,  66, 260,  ..., 261, 261, 261],\n",
       "           [259, 115, 102,  ..., 261, 261, 261],\n",
       "           [259, 116, 112,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  80, 113,  ..., 261, 261, 261],\n",
       "           [259, 227, 129,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259, 227, 129,  ..., 261, 261, 261],\n",
       "           [259, 195, 163,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261]],\n",
       "  \n",
       "          [[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  81, 109,  ..., 261, 261, 261],\n",
       "           [259, 101, 112,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]]])},\n",
       " 'id': ['00a1aabcab9d44a0',\n",
       "  '0084d905b6f19f2b',\n",
       "  '0063f77040fbc7d4',\n",
       "  '00397b264deba890',\n",
       "  '0097dd5c29bf7a15',\n",
       "  '0010833a96e1f886',\n",
       "  '00229d44f41f3acb',\n",
       "  '003910ffa2f50517',\n",
       "  '005ba6af463ab6cf',\n",
       "  '003f698d06c9b180',\n",
       "  '0044cf18cc2655b3',\n",
       "  '00a98913b0b8ba34',\n",
       "  '00031b1e95af7921',\n",
       "  '00803f08f55bdcad',\n",
       "  '0011cc71398479c4',\n",
       "  '008a990457283850',\n",
       "  '0009801bd85e5806',\n",
       "  '00562e78e0b34102',\n",
       "  '006cf8c9f4cc4d57',\n",
       "  '008e0818dde894fb',\n",
       "  '0071cd1ca07040ab',\n",
       "  '001c557175094f10',\n",
       "  '007ecbb379c4a861',\n",
       "  '0034d7c78cfa6dee',\n",
       "  '0060ef190ee10720',\n",
       "  '0035d638ba684122',\n",
       "  '00604eb295a1dbf2',\n",
       "  '000eefc67a2c930f',\n",
       "  '000103f0d9cfb60f',\n",
       "  '00958dec64c33224',\n",
       "  '007094f2f9efe035',\n",
       "  '0050cb3bc226f94e',\n",
       "  '0048e4ed8a0af433',\n",
       "  '00686325bcc16080',\n",
       "  '006493e4e9c89cab',\n",
       "  '003caacc6ce6c9e9',\n",
       "  '001dc38a83d420cf',\n",
       "  '006fc8cfaa4faf0b',\n",
       "  '00290e2a171dd073',\n",
       "  '00169857adbc989b',\n",
       "  '004fb9f655230909',\n",
       "  '0053978373606ba4',\n",
       "  '009371b0ef213487',\n",
       "  '004a23742282fee4',\n",
       "  '009a52daa8dbb767',\n",
       "  '006b94add72ed61c',\n",
       "  '0097b052f0b68a96',\n",
       "  '0010307a3a50a353',\n",
       "  '008a856f6691e051',\n",
       "  '00a216c00b90ce88',\n",
       "  '0073059e6433db47',\n",
       "  '001e89eb3f0b0915',\n",
       "  '004fd4fb5c47c29f',\n",
       "  '0090c1f0788dd0e9',\n",
       "  '002918ae66cc4bc2',\n",
       "  '00316bcc0d1bc6e0',\n",
       "  '0066dcf7d9ecd360',\n",
       "  '003d77a20601cec1',\n",
       "  '009a6b3e571ee155',\n",
       "  '006b77d41eb4bc08',\n",
       "  '001735f961a23fc4',\n",
       "  '00548d029d7f4783',\n",
       "  '002a13f2896596fa',\n",
       "  '006fda507acd9769'],\n",
       " 'label': tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  90, 102,  ..., 261, 261, 261],\n",
       "         [259, 117, 105,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  74, 260,  ..., 261, 261, 261],\n",
       "         [259,  71,  74,  ..., 261, 261, 261],\n",
       "         [259,  74,  85,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  71, 115,  ..., 261, 261, 261],\n",
       "         [259, 100, 109,  ..., 261, 261, 261],\n",
       "         [259,  74, 260,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[259,  66, 260,  ..., 261, 261, 261],\n",
       "         [259, 115, 102,  ..., 261, 261, 261],\n",
       "         [259, 116, 112,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  80, 113,  ..., 261, 261, 261],\n",
       "         [259, 227, 129,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 227, 129,  ..., 261, 261, 261],\n",
       "         [259, 195, 163,  ..., 261, 261, 261],\n",
       "         [259,  35, 260,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  81, 109,  ..., 261, 261, 261],\n",
       "         [259, 101, 112,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 45, 50])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "\n",
    "class BaselineModel(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 out_sz: int=len(label_cols)):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
    "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        state = self.encoder(embeddings, mask)\n",
    "        class_logits = self.projection(state)\n",
    "        \n",
    "        output = {\"class_logits\": class_logits}\n",
    "        output[\"loss\"] = self.loss(class_logits, label)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/03/2019 17:30:50 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "\n",
    "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how simple and modular the code for initializing the model is. All the complexity is delegated to each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda()\n",
    "else: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  90, 102,  ..., 261, 261, 261],\n",
       "          [259, 117, 105,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  74, 260,  ..., 261, 261, 261],\n",
       "          [259,  71,  74,  ..., 261, 261, 261],\n",
       "          [259,  74,  85,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  71, 115,  ..., 261, 261, 261],\n",
       "          [259, 100, 109,  ..., 261, 261, 261],\n",
       "          [259,  74, 260,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[259,  66, 260,  ..., 261, 261, 261],\n",
       "          [259, 115, 102,  ..., 261, 261, 261],\n",
       "          [259, 116, 112,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  80, 113,  ..., 261, 261, 261],\n",
       "          [259, 227, 129,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [259, 227, 129,  ..., 261, 261, 261],\n",
       "          [259, 195, 163,  ..., 261, 261, 261],\n",
       "          [259,  35, 260,  ..., 261, 261, 261]],\n",
       " \n",
       "         [[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  81, 109,  ..., 261, 261, 261],\n",
       "          [259, 101, 112,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = get_text_field_mask(tokens)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.0163e-02,  6.4747e-02,  2.6297e-01, -1.6403e-02,  1.9168e-02,\n",
       "         -1.6628e-01],\n",
       "        [ 9.5824e-02,  8.7803e-02,  2.4718e-02,  3.7297e-02,  6.7119e-02,\n",
       "         -2.0273e-01],\n",
       "        [-6.7574e-02,  1.5751e-01,  1.0635e-01, -4.4015e-03,  1.4845e-02,\n",
       "         -3.1285e-02],\n",
       "        [-1.0367e-03, -5.3197e-02, -1.2650e-02,  2.0672e-01,  9.8254e-02,\n",
       "         -7.4023e-02],\n",
       "        [-9.9698e-02,  5.6070e-02,  6.4787e-02, -1.1896e-01,  5.9189e-03,\n",
       "         -1.0728e-01],\n",
       "        [-1.6731e-01,  1.9377e-02,  1.6526e-01, -8.5814e-02,  1.1862e-01,\n",
       "         -2.2048e-01],\n",
       "        [ 6.0305e-02,  6.5591e-02, -4.8577e-02, -8.1078e-02,  1.0256e-01,\n",
       "         -1.1554e-01],\n",
       "        [ 2.7622e-02, -1.1867e-02,  9.7557e-02,  5.0214e-02,  2.7249e-02,\n",
       "         -1.0539e-01],\n",
       "        [ 6.2683e-02, -1.0014e-01,  2.0654e-01,  1.2998e-01,  9.3514e-02,\n",
       "         -4.2657e-03],\n",
       "        [-7.0279e-02, -6.9139e-02, -3.1017e-02, -2.8966e-02,  7.2114e-02,\n",
       "          1.9947e-02],\n",
       "        [-1.1726e-01,  1.3738e-01,  5.0743e-02,  6.5252e-02,  1.1664e-01,\n",
       "         -1.0845e-01],\n",
       "        [ 2.9818e-02, -1.0703e-01,  1.5059e-01,  1.5396e-02,  1.4500e-01,\n",
       "         -1.1675e-01],\n",
       "        [ 1.5082e-01, -2.3876e-02,  1.0486e-01, -1.6658e-01,  8.5563e-02,\n",
       "         -1.7842e-01],\n",
       "        [-2.1506e-02,  1.3648e-02,  8.0151e-02, -1.8986e-02, -1.8607e-01,\n",
       "         -9.1134e-02],\n",
       "        [ 2.8120e-02,  4.8619e-02,  9.1153e-02,  1.7597e-01,  5.6350e-02,\n",
       "         -2.2981e-01],\n",
       "        [-1.8429e-02,  7.9775e-02, -1.1394e-01, -4.8520e-02,  1.6643e-01,\n",
       "         -9.9189e-02],\n",
       "        [ 8.2103e-02, -6.8350e-02,  1.3524e-01,  7.6897e-02, -7.7527e-03,\n",
       "         -8.9668e-02],\n",
       "        [-2.1986e-02,  1.0673e-01, -2.0711e-02, -3.2987e-03,  1.5663e-01,\n",
       "         -6.3086e-02],\n",
       "        [ 3.0311e-02, -8.6179e-03, -4.4777e-02, -5.1902e-02,  1.5227e-01,\n",
       "          9.3593e-03],\n",
       "        [-6.5456e-02,  1.0269e-01,  2.2504e-01, -6.3303e-02,  5.8412e-02,\n",
       "         -1.8505e-01],\n",
       "        [ 5.4153e-02,  7.3936e-02,  1.3877e-01,  1.8259e-01, -1.9579e-01,\n",
       "          1.8800e-02],\n",
       "        [-1.1696e-01, -2.3658e-02,  7.6509e-02,  1.7122e-03,  1.7194e-01,\n",
       "         -2.1046e-01],\n",
       "        [ 1.1723e-02, -8.8490e-03,  1.7730e-01,  6.5812e-02,  3.7379e-02,\n",
       "         -5.0502e-02],\n",
       "        [ 1.3112e-01, -2.0793e-01,  7.8499e-02, -1.3814e-02,  7.7267e-02,\n",
       "         -1.5076e-02],\n",
       "        [-7.7421e-02, -6.3760e-02,  5.4665e-02, -3.0373e-02, -6.4172e-02,\n",
       "         -1.2707e-01],\n",
       "        [ 1.7184e-02,  2.2053e-02, -8.3055e-02,  9.8727e-02,  2.2831e-01,\n",
       "         -5.1344e-02],\n",
       "        [-1.7602e-02,  3.0323e-02,  2.6863e-02, -4.5041e-03,  9.8123e-02,\n",
       "         -1.3989e-01],\n",
       "        [-3.7932e-02,  5.8749e-02,  8.4022e-02, -7.2774e-02,  6.8128e-02,\n",
       "          6.7143e-02],\n",
       "        [-9.2882e-02,  1.4170e-02, -1.1339e-01,  5.2145e-02,  2.3146e-02,\n",
       "         -2.1000e-01],\n",
       "        [ 8.1589e-03,  1.7353e-02, -1.9937e-02, -2.2717e-02, -8.7968e-02,\n",
       "          1.7048e-02],\n",
       "        [-9.1245e-02,  3.6261e-02,  7.6664e-02, -7.7030e-02,  2.6744e-01,\n",
       "         -1.6949e-01],\n",
       "        [-2.5427e-02, -2.7534e-02,  6.9697e-02,  6.6503e-02,  1.1419e-01,\n",
       "         -1.4283e-02],\n",
       "        [ 3.1063e-02, -3.8424e-02,  7.4862e-02, -3.0738e-02, -6.7676e-02,\n",
       "         -1.6888e-01],\n",
       "        [-5.9841e-02,  5.0211e-02, -2.0227e-02, -1.2721e-01, -1.4570e-01,\n",
       "         -2.4007e-01],\n",
       "        [-5.7110e-02, -4.3528e-02,  3.4237e-04, -9.5658e-02,  2.4990e-01,\n",
       "         -1.1733e-01],\n",
       "        [-1.0550e-02,  8.4521e-02,  2.7159e-03, -4.9407e-02,  2.7698e-02,\n",
       "         -1.4040e-01],\n",
       "        [-3.9085e-02,  2.2019e-01,  1.8157e-01,  1.6213e-01,  8.9227e-02,\n",
       "         -1.2565e-01],\n",
       "        [-8.2843e-02, -2.8791e-02, -4.5698e-02,  1.8817e-02,  4.4470e-02,\n",
       "         -9.0937e-02],\n",
       "        [ 1.2195e-02,  6.4299e-02,  6.7748e-02, -8.8808e-03, -6.8256e-02,\n",
       "         -1.0327e-01],\n",
       "        [-1.1683e-02,  3.8981e-02,  7.8335e-02,  1.0622e-01,  9.2133e-02,\n",
       "          4.1637e-02],\n",
       "        [-1.2862e-01,  1.0034e-02, -4.9060e-02, -8.2797e-02,  1.5333e-01,\n",
       "         -1.4500e-01],\n",
       "        [ 3.1619e-02, -6.6060e-02,  7.3614e-02, -1.0534e-01,  9.8841e-02,\n",
       "         -3.3543e-02],\n",
       "        [ 5.8931e-04,  2.6711e-02,  1.1954e-01,  1.4609e-01,  6.0656e-02,\n",
       "         -6.2100e-02],\n",
       "        [ 2.4279e-02, -1.5198e-01,  2.1131e-01, -7.5665e-02,  7.3169e-02,\n",
       "         -1.7503e-01],\n",
       "        [-1.4678e-01,  8.8429e-02,  1.9124e-01, -2.4170e-02,  6.2735e-02,\n",
       "          4.4073e-03],\n",
       "        [ 5.0885e-02,  1.1894e-01,  2.2267e-01,  1.5435e-02, -1.7662e-01,\n",
       "         -3.0214e-01],\n",
       "        [ 1.0864e-01, -6.7574e-02,  6.4472e-02, -1.0615e-01,  1.5382e-01,\n",
       "         -2.9311e-01],\n",
       "        [ 9.1749e-02,  1.2318e-02,  1.3463e-01,  5.2623e-02, -6.8676e-02,\n",
       "         -2.6478e-01],\n",
       "        [ 1.7675e-02, -4.8747e-02, -6.3604e-02,  5.2108e-02, -9.2010e-03,\n",
       "         -1.6669e-01],\n",
       "        [-1.9043e-01, -9.0172e-02, -9.0555e-02,  1.1761e-01,  9.0321e-02,\n",
       "          1.5747e-02],\n",
       "        [ 4.9259e-02, -7.9496e-02,  3.3560e-02,  1.3965e-01, -4.4191e-03,\n",
       "          1.2972e-01],\n",
       "        [-2.9381e-02,  6.0331e-02, -3.3569e-02, -7.4291e-02,  3.4855e-02,\n",
       "         -7.6973e-02],\n",
       "        [-1.0348e-01,  2.2813e-01,  1.5227e-01, -1.9455e-02, -5.0248e-02,\n",
       "         -1.7153e-01],\n",
       "        [ 6.8606e-02,  5.4623e-02,  1.5979e-01,  9.2505e-04, -6.3158e-03,\n",
       "         -1.0248e-01],\n",
       "        [ 1.2381e-01,  6.0454e-02,  1.8540e-01,  8.0185e-02,  2.6962e-02,\n",
       "         -5.1625e-02],\n",
       "        [-1.1420e-01,  8.7726e-02,  4.0912e-02, -3.8961e-02, -3.7743e-02,\n",
       "         -7.1318e-02],\n",
       "        [ 4.3321e-05,  1.3892e-02,  1.1231e-01, -9.2448e-02, -3.3143e-02,\n",
       "         -1.2253e-01],\n",
       "        [-1.4132e-01,  2.0278e-01,  1.2699e-02,  2.1149e-01, -2.5147e-02,\n",
       "         -7.2530e-02],\n",
       "        [ 3.7882e-02, -7.4940e-02,  1.6940e-01, -1.5170e-01,  1.1054e-02,\n",
       "         -3.9091e-02],\n",
       "        [ 6.2380e-02, -9.7099e-02,  1.0262e-01,  9.9262e-05,  1.4400e-01,\n",
       "         -1.3110e-02],\n",
       "        [-5.3205e-02,  1.1376e-01, -9.0863e-02, -1.4401e-01, -2.3331e-02,\n",
       "         -7.9893e-02],\n",
       "        [ 4.1971e-02, -8.4530e-02,  2.0034e-01, -1.2370e-01,  1.6637e-01,\n",
       "         -8.0638e-02],\n",
       "        [-5.7683e-02,  1.8108e-01,  2.2032e-01, -4.8055e-02, -3.9169e-02,\n",
       "         -1.0132e-01],\n",
       "        [-8.4454e-02,  2.0587e-01, -7.1434e-03, -1.1960e-02, -1.7229e-01,\n",
       "         -1.5894e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.word_embeddings(tokens)\n",
    "state = model.encoder(embeddings, mask)\n",
    "class_logits = model.projection(state)\n",
    "class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_logits': tensor([[-3.4829e-02,  5.2497e-02,  2.2299e-01, -1.8890e-01, -2.0429e-03,\n",
       "          -7.4547e-02],\n",
       "         [ 1.3691e-01,  2.1239e-02,  2.3981e-02,  2.1327e-02,  2.0890e-02,\n",
       "          -1.8907e-01],\n",
       "         [-1.7149e-01,  8.6617e-03,  4.0481e-02, -7.7425e-02, -4.0966e-02,\n",
       "          -1.1208e-01],\n",
       "         [-3.6241e-02, -6.5557e-02, -7.7019e-02,  4.4819e-02,  3.3430e-02,\n",
       "          -2.4298e-01],\n",
       "         [-8.3382e-02,  7.1285e-02,  1.7028e-01, -6.6278e-02,  1.2807e-01,\n",
       "          -1.9301e-01],\n",
       "         [-1.2943e-01, -8.1146e-02,  7.5968e-02, -3.1295e-02, -7.5692e-02,\n",
       "          -1.4631e-01],\n",
       "         [ 1.2931e-02,  1.1064e-01,  3.3163e-02, -3.6950e-02, -2.4099e-02,\n",
       "          -1.3883e-01],\n",
       "         [ 5.2409e-02,  1.0081e-01,  2.1262e-02, -8.8295e-02, -2.6079e-02,\n",
       "          -7.9742e-02],\n",
       "         [ 2.2081e-02, -1.3706e-01,  1.7494e-01,  5.8705e-02,  3.2575e-02,\n",
       "          -6.8659e-02],\n",
       "         [ 7.9164e-02, -6.5224e-02,  7.3719e-02, -5.4167e-02,  1.5824e-01,\n",
       "           8.0593e-03],\n",
       "         [-6.4973e-03,  6.1593e-02,  6.2622e-02, -9.4827e-02,  1.0093e-01,\n",
       "          -1.6325e-01],\n",
       "         [-8.2546e-02, -1.4218e-01,  2.0023e-01,  3.5476e-02,  2.7713e-01,\n",
       "          -2.7120e-01],\n",
       "         [ 9.0740e-02,  4.3491e-02,  1.4422e-01,  6.0931e-02,  4.5855e-02,\n",
       "          -1.1539e-01],\n",
       "         [-5.3089e-02,  6.5307e-02,  8.0208e-02, -3.9650e-02, -2.8217e-01,\n",
       "          -8.9820e-02],\n",
       "         [ 5.5250e-02,  8.6744e-02, -1.0727e-01,  1.4565e-01,  1.9570e-01,\n",
       "          -1.8735e-01],\n",
       "         [-7.8439e-02,  1.3161e-02,  7.5172e-02, -5.4252e-02,  1.7791e-01,\n",
       "          -1.3568e-01],\n",
       "         [ 5.1995e-02,  2.9064e-02,  1.4172e-01,  1.4304e-01, -5.8937e-02,\n",
       "          -7.3282e-02],\n",
       "         [ 1.7174e-03, -2.8379e-02, -1.2541e-01, -4.5639e-02,  4.7234e-02,\n",
       "          -5.2116e-02],\n",
       "         [ 3.5427e-02, -9.2231e-02,  8.2086e-02, -2.1343e-02,  2.7887e-01,\n",
       "          -1.5167e-01],\n",
       "         [-6.1626e-02, -2.5624e-02,  2.2388e-04, -4.1693e-02, -4.9399e-02,\n",
       "          -4.0510e-02],\n",
       "         [-1.4762e-01,  1.9422e-01,  1.1742e-01,  6.9093e-02, -2.4592e-02,\n",
       "          -1.0059e-01],\n",
       "         [ 3.8874e-02,  8.2074e-02,  1.9104e-02, -2.5636e-02, -3.2118e-02,\n",
       "          -1.6910e-01],\n",
       "         [-4.8922e-02, -7.5088e-02,  1.8210e-01,  7.3574e-04,  1.5744e-01,\n",
       "          -1.3788e-02],\n",
       "         [-1.2497e-01, -2.4336e-01, -2.4353e-02,  7.5085e-02, -6.1093e-02,\n",
       "          -1.4074e-02],\n",
       "         [-1.6153e-01, -6.2217e-02,  1.7573e-02,  4.1915e-02, -4.5269e-02,\n",
       "          -1.6788e-01],\n",
       "         [-3.9241e-02,  3.5563e-02, -1.1499e-01,  8.6545e-02,  1.1759e-01,\n",
       "          -2.4759e-01],\n",
       "         [-2.5791e-02, -1.9676e-02, -5.6730e-02, -8.6068e-02,  1.3879e-01,\n",
       "           6.2217e-02],\n",
       "         [-1.8551e-01, -2.2499e-02,  1.0650e-01, -6.6553e-02,  5.6888e-02,\n",
       "           2.0960e-02],\n",
       "         [ 1.3009e-01, -1.2827e-02,  5.7639e-02, -1.3761e-02, -4.3420e-02,\n",
       "           1.0038e-02],\n",
       "         [ 7.0067e-02,  8.4126e-02, -4.2292e-02,  7.9704e-02,  1.8087e-01,\n",
       "          -1.2272e-01],\n",
       "         [-7.4725e-02,  9.6880e-02,  8.2236e-02, -2.0754e-01,  4.2494e-02,\n",
       "          -2.9941e-01],\n",
       "         [-1.6016e-01, -7.1483e-03, -8.1070e-02,  2.3778e-02,  6.8444e-03,\n",
       "          -5.6978e-02],\n",
       "         [ 6.3472e-02, -2.5701e-02,  5.9843e-02,  6.6319e-02, -1.8325e-02,\n",
       "          -2.0568e-01],\n",
       "         [-3.5410e-02, -4.7817e-02, -5.6710e-02, -5.7028e-02, -5.1373e-02,\n",
       "          -2.8230e-01],\n",
       "         [-4.7199e-02,  7.2429e-02,  1.4289e-01,  3.4596e-02,  9.5697e-02,\n",
       "          -3.1584e-01],\n",
       "         [ 4.3169e-02,  8.2035e-02,  1.1176e-01,  1.0481e-03, -1.1210e-01,\n",
       "          -1.7873e-01],\n",
       "         [-6.2943e-02,  8.6012e-02,  1.7348e-01,  8.8144e-02, -3.8238e-02,\n",
       "          -2.3425e-01],\n",
       "         [ 4.7357e-02,  1.0746e-01,  5.6155e-02,  1.9163e-01,  7.5852e-02,\n",
       "          -2.8337e-02],\n",
       "         [ 1.8409e-02,  1.5300e-01,  9.2675e-03, -4.5621e-02, -2.0527e-02,\n",
       "          -1.5282e-01],\n",
       "         [-4.7619e-02,  2.6486e-02,  1.2573e-01, -1.4631e-02,  1.4592e-01,\n",
       "          -1.0759e-03],\n",
       "         [-7.2680e-02, -1.9204e-02, -9.8405e-02, -1.3119e-01,  1.2309e-01,\n",
       "          -9.5634e-02],\n",
       "         [ 1.1575e-03, -7.8500e-03,  1.2278e-01, -4.7101e-02,  1.2488e-01,\n",
       "          -5.7243e-02],\n",
       "         [ 2.0911e-02, -1.1552e-02, -3.8555e-02,  1.0575e-01,  9.4579e-03,\n",
       "           6.7739e-02],\n",
       "         [ 4.7413e-02, -4.8376e-02,  6.5095e-02,  3.1140e-02,  7.2354e-02,\n",
       "           1.3792e-01],\n",
       "         [-8.9262e-02,  1.7584e-02,  1.4604e-01,  1.0318e-01,  1.2221e-01,\n",
       "           9.3683e-02],\n",
       "         [-9.9532e-02,  1.8598e-03,  4.0683e-02, -1.0138e-01, -3.4947e-02,\n",
       "          -1.2899e-01],\n",
       "         [ 4.5695e-02,  5.3425e-03,  1.3365e-01, -3.7057e-02, -1.2203e-02,\n",
       "          -1.2999e-01],\n",
       "         [ 1.3325e-02,  9.6191e-02,  2.3047e-01, -1.3150e-01,  1.0473e-01,\n",
       "          -1.0105e-01],\n",
       "         [-1.8679e-02,  1.3529e-02,  1.3032e-01, -9.8955e-02,  9.3013e-03,\n",
       "          -2.2546e-01],\n",
       "         [-7.4999e-02, -6.3174e-02, -1.5645e-01,  4.9242e-02, -5.5602e-03,\n",
       "          -6.5774e-02],\n",
       "         [ 1.3472e-01, -9.2984e-02,  5.8929e-02,  3.5098e-02,  9.2470e-02,\n",
       "          -5.6237e-02],\n",
       "         [-1.6999e-02,  1.1777e-01, -4.5761e-02,  6.3658e-02, -3.1722e-02,\n",
       "          -3.1553e-01],\n",
       "         [-6.8944e-02,  2.1890e-01,  1.6621e-01, -7.9067e-02,  1.1897e-02,\n",
       "          -1.9201e-01],\n",
       "         [ 1.2454e-01, -2.5155e-02,  4.2642e-02, -6.5565e-02,  9.9036e-02,\n",
       "          -1.6324e-01],\n",
       "         [ 4.4231e-02, -3.4978e-02,  3.3161e-02, -1.7917e-02, -5.2784e-04,\n",
       "          -1.2203e-01],\n",
       "         [-8.4801e-02, -2.1339e-03,  3.6362e-02,  1.1369e-01, -5.1517e-02,\n",
       "          -6.6739e-02],\n",
       "         [ 8.2710e-02,  1.2471e-01,  3.0893e-01,  8.0587e-03,  1.2071e-01,\n",
       "          -5.0028e-02],\n",
       "         [ 9.1359e-02,  1.8617e-01, -1.6877e-01, -1.4966e-02, -2.1014e-02,\n",
       "          -1.1205e-01],\n",
       "         [ 3.6277e-02, -2.7988e-02,  2.3931e-02, -1.6690e-01,  2.1195e-02,\n",
       "          -1.2250e-01],\n",
       "         [ 9.2705e-02, -8.8818e-02,  1.0082e-01, -7.0644e-02,  7.3441e-02,\n",
       "           8.2808e-02],\n",
       "         [ 2.8261e-02,  3.3999e-02,  6.5985e-02, -1.4783e-01, -5.9896e-02,\n",
       "          -2.1173e-01],\n",
       "         [-6.5725e-02,  1.0629e-01,  3.8118e-02,  3.8209e-02,  5.9097e-02,\n",
       "          -7.5223e-02],\n",
       "         [-9.7074e-02,  6.1381e-02,  1.6832e-01, -7.5067e-02, -1.7879e-02,\n",
       "          -4.8182e-02],\n",
       "         [-9.8257e-02,  7.7614e-02,  8.4950e-02,  8.3247e-03,  7.1985e-02,\n",
       "          -2.5099e-01]], grad_fn=<AddmmBackward>),\n",
       " 'loss': tensor(0.6935, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**batch)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6972, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.3974e-05,  1.1389e-05,  4.9973e-05,  ..., -7.9098e-05,\n",
       "           4.7838e-05, -1.9684e-05],\n",
       "         [-1.2166e-04, -6.3747e-05, -1.2056e-04,  ..., -1.2964e-04,\n",
       "           1.3664e-04, -6.8199e-05],\n",
       "         [-1.3146e-04,  9.1971e-05,  3.6641e-05,  ...,  6.4251e-05,\n",
       "           1.5939e-04,  8.8090e-05],\n",
       "         ...,\n",
       "         [ 2.5123e-04, -4.7318e-05,  5.9469e-05,  ..., -1.0526e-04,\n",
       "          -2.5753e-04,  6.4145e-05],\n",
       "         [-5.1145e-05, -1.0931e-05,  6.5940e-05,  ..., -2.3286e-05,\n",
       "           9.6785e-05,  5.9618e-06],\n",
       "         [ 1.0809e-04,  1.0349e-05,  4.6627e-05,  ..., -3.2571e-05,\n",
       "          -1.3261e-04,  1.2602e-04]]),\n",
       " tensor([[ 1.0903e-05,  1.2475e-05, -2.9365e-06,  ..., -1.1445e-05,\n",
       "           1.9748e-05, -8.9563e-06],\n",
       "         [-1.5088e-05,  2.9193e-05, -5.3877e-05,  ..., -1.3567e-05,\n",
       "          -4.9185e-06,  4.6052e-06],\n",
       "         [ 7.9974e-06,  3.5755e-07, -6.2460e-05,  ..., -2.5084e-05,\n",
       "           5.9656e-06,  3.7861e-05],\n",
       "         ...,\n",
       "         [-6.7549e-06,  1.0008e-05,  1.2176e-04,  ...,  1.7985e-04,\n",
       "           8.0755e-06, -7.0324e-05],\n",
       "         [ 3.8369e-05, -1.5413e-05,  7.6452e-07,  ..., -1.3645e-05,\n",
       "          -2.4191e-05, -3.7354e-06],\n",
       "         [ 1.2299e-06,  6.9348e-05,  5.5453e-05,  ...,  2.0402e-06,\n",
       "          -1.8248e-06, -9.5014e-05]]),\n",
       " tensor([-3.0109e-05, -1.9663e-04, -4.0238e-04, -9.0053e-05,  1.8247e-04,\n",
       "         -1.0074e-04,  1.8359e-04,  9.8899e-05, -6.1298e-05, -3.4345e-05,\n",
       "          5.1333e-04,  4.0692e-04,  3.8163e-05, -2.9328e-04,  1.8027e-04,\n",
       "         -4.9062e-04, -2.9180e-05,  1.8176e-04,  5.8489e-04, -5.0065e-05,\n",
       "          3.7946e-06, -1.0156e-04, -5.7518e-05, -3.4633e-04, -2.8740e-05,\n",
       "         -8.7021e-05, -2.0527e-04, -7.5257e-04,  1.6313e-04,  3.7052e-04,\n",
       "         -2.2226e-04,  2.1567e-04, -1.5528e-04,  1.7062e-04, -7.3154e-05,\n",
       "          1.0402e-04, -4.1885e-04,  7.1251e-05,  8.9611e-05, -8.1197e-06,\n",
       "         -2.3998e-04, -8.7407e-05, -5.4428e-05, -2.0377e-04, -4.4930e-05,\n",
       "          7.1343e-07,  1.4179e-04, -3.2348e-05, -1.0510e-03,  1.1077e-04,\n",
       "          2.5152e-04, -3.3601e-05,  2.1386e-04,  1.2588e-04,  9.1279e-05,\n",
       "          5.7150e-04, -1.6846e-04,  2.9687e-04,  1.4177e-04, -4.2065e-05,\n",
       "         -1.3009e-04,  3.9166e-04, -7.7377e-06,  2.7601e-04, -1.2949e-04,\n",
       "          1.1393e-04, -3.0537e-04, -7.2536e-05,  4.0019e-04, -1.2577e-04,\n",
       "         -6.4553e-05, -9.1679e-06,  3.1827e-04,  2.5652e-04,  4.0153e-04,\n",
       "          1.5436e-04, -1.4249e-04, -1.1381e-03,  6.3284e-04, -4.4886e-04,\n",
       "          1.6406e-05,  2.4965e-04,  5.9968e-04, -6.3839e-05,  1.0890e-04,\n",
       "         -2.0496e-05,  1.0659e-04, -2.6989e-04, -4.9543e-05, -2.5032e-04,\n",
       "         -2.4535e-04, -4.3657e-04,  1.2255e-04,  1.1802e-04, -2.0595e-04,\n",
       "          1.7730e-04, -2.1089e-04,  2.3854e-04,  4.9448e-07,  7.0943e-05,\n",
       "         -3.2820e-04,  8.1429e-05,  4.5518e-04, -4.0438e-05, -5.1825e-04,\n",
       "         -4.1309e-05, -3.4302e-05, -2.4599e-04,  1.1513e-04,  9.1252e-06,\n",
       "          4.3544e-05,  1.1571e-05, -8.2852e-04,  3.3707e-05,  1.3798e-04,\n",
       "         -3.8381e-05,  2.3824e-04,  1.2793e-05,  1.1095e-04,  7.4956e-04,\n",
       "         -9.5034e-05,  2.0969e-04,  9.9925e-05, -1.1662e-04,  9.9280e-06,\n",
       "          4.6754e-05, -3.2338e-05,  5.2459e-04,  3.7085e-03,  4.1075e-03,\n",
       "         -1.2232e-03,  4.8846e-04, -3.3265e-03,  2.8984e-03, -5.6264e-03,\n",
       "         -1.1652e-03,  4.7548e-03, -2.5635e-03, -3.3730e-03, -4.4694e-03,\n",
       "         -1.0487e-02, -4.3990e-03, -7.6412e-03,  4.3403e-03, -4.7708e-05,\n",
       "          9.4774e-04, -2.3490e-03,  6.1761e-03, -2.3459e-03, -2.7141e-03,\n",
       "          5.0079e-03,  2.9917e-03, -1.3224e-04, -4.9899e-03,  3.7369e-03,\n",
       "         -4.3257e-03, -9.6943e-04, -1.3769e-03,  1.4718e-03, -1.1774e-03,\n",
       "          1.9898e-03,  1.6162e-03,  1.9842e-03, -1.0242e-03, -2.5103e-03,\n",
       "          3.8040e-04, -2.3581e-03, -1.3877e-03,  3.2959e-03, -3.2832e-03,\n",
       "         -4.9646e-05,  1.5272e-03,  2.7060e-03, -5.3892e-04, -1.7320e-05,\n",
       "          8.8892e-05, -3.9011e-03,  1.6642e-04, -2.3966e-03, -8.1226e-04,\n",
       "         -2.9875e-03,  4.5100e-03,  1.2847e-03,  1.5020e-03,  1.3109e-03,\n",
       "          3.7009e-03,  1.0019e-03,  1.3826e-03,  1.4400e-03,  2.1941e-03,\n",
       "         -1.6402e-03, -3.6665e-03, -1.0909e-04, -3.0021e-04, -4.5087e-04,\n",
       "         -6.2716e-05,  2.4222e-04, -7.3136e-05,  2.7222e-04,  1.0244e-04,\n",
       "         -1.1157e-04,  2.0240e-05,  3.9633e-04,  2.4952e-04, -2.3172e-04,\n",
       "         -4.9703e-04,  2.0433e-04, -7.7613e-04, -1.1396e-05,  2.0476e-04,\n",
       "          8.6149e-04, -1.9618e-04,  4.9280e-05, -7.5172e-05, -3.2694e-05,\n",
       "         -4.6390e-04, -4.3287e-05, -2.0254e-04, -2.6813e-04, -9.3772e-04,\n",
       "          1.9864e-04,  3.3830e-04, -1.6404e-04,  2.0949e-04, -2.2491e-04,\n",
       "          2.0077e-04, -2.0348e-04,  1.5902e-04, -6.1057e-04,  4.6627e-05,\n",
       "          1.4975e-04, -3.9675e-05, -3.2065e-04, -1.2347e-04, -5.2877e-05,\n",
       "         -2.9591e-04, -1.0278e-04, -1.8351e-05,  1.2279e-04, -5.4820e-05,\n",
       "         -1.8323e-03,  1.4336e-04,  5.5230e-04, -7.6677e-06,  3.1774e-04,\n",
       "         -4.0496e-05,  1.1737e-04,  8.8052e-04, -1.7388e-04,  4.1311e-04,\n",
       "          1.5164e-04, -8.8825e-05, -1.1965e-04,  8.5245e-04, -1.9150e-05,\n",
       "          3.8796e-04]),\n",
       " tensor([-3.0109e-05, -1.9663e-04, -4.0238e-04, -9.0053e-05,  1.8247e-04,\n",
       "         -1.0074e-04,  1.8359e-04,  9.8899e-05, -6.1298e-05, -3.4345e-05,\n",
       "          5.1333e-04,  4.0692e-04,  3.8163e-05, -2.9328e-04,  1.8027e-04,\n",
       "         -4.9062e-04, -2.9180e-05,  1.8176e-04,  5.8489e-04, -5.0065e-05,\n",
       "          3.7946e-06, -1.0156e-04, -5.7518e-05, -3.4633e-04, -2.8740e-05,\n",
       "         -8.7021e-05, -2.0527e-04, -7.5257e-04,  1.6313e-04,  3.7052e-04,\n",
       "         -2.2226e-04,  2.1567e-04, -1.5528e-04,  1.7062e-04, -7.3154e-05,\n",
       "          1.0402e-04, -4.1885e-04,  7.1251e-05,  8.9611e-05, -8.1197e-06,\n",
       "         -2.3998e-04, -8.7407e-05, -5.4428e-05, -2.0377e-04, -4.4930e-05,\n",
       "          7.1343e-07,  1.4179e-04, -3.2348e-05, -1.0510e-03,  1.1077e-04,\n",
       "          2.5152e-04, -3.3601e-05,  2.1386e-04,  1.2588e-04,  9.1279e-05,\n",
       "          5.7150e-04, -1.6846e-04,  2.9687e-04,  1.4177e-04, -4.2065e-05,\n",
       "         -1.3009e-04,  3.9166e-04, -7.7377e-06,  2.7601e-04, -1.2949e-04,\n",
       "          1.1393e-04, -3.0537e-04, -7.2536e-05,  4.0019e-04, -1.2577e-04,\n",
       "         -6.4553e-05, -9.1679e-06,  3.1827e-04,  2.5652e-04,  4.0153e-04,\n",
       "          1.5436e-04, -1.4249e-04, -1.1381e-03,  6.3284e-04, -4.4886e-04,\n",
       "          1.6406e-05,  2.4965e-04,  5.9968e-04, -6.3839e-05,  1.0890e-04,\n",
       "         -2.0496e-05,  1.0659e-04, -2.6989e-04, -4.9543e-05, -2.5032e-04,\n",
       "         -2.4535e-04, -4.3657e-04,  1.2255e-04,  1.1802e-04, -2.0595e-04,\n",
       "          1.7730e-04, -2.1089e-04,  2.3854e-04,  4.9448e-07,  7.0943e-05,\n",
       "         -3.2820e-04,  8.1429e-05,  4.5518e-04, -4.0438e-05, -5.1825e-04,\n",
       "         -4.1309e-05, -3.4302e-05, -2.4599e-04,  1.1513e-04,  9.1252e-06,\n",
       "          4.3544e-05,  1.1571e-05, -8.2852e-04,  3.3707e-05,  1.3798e-04,\n",
       "         -3.8381e-05,  2.3824e-04,  1.2793e-05,  1.1095e-04,  7.4956e-04,\n",
       "         -9.5034e-05,  2.0969e-04,  9.9925e-05, -1.1662e-04,  9.9280e-06,\n",
       "          4.6754e-05, -3.2338e-05,  5.2459e-04,  3.7085e-03,  4.1075e-03,\n",
       "         -1.2232e-03,  4.8846e-04, -3.3265e-03,  2.8984e-03, -5.6264e-03,\n",
       "         -1.1652e-03,  4.7548e-03, -2.5635e-03, -3.3730e-03, -4.4694e-03,\n",
       "         -1.0487e-02, -4.3990e-03, -7.6412e-03,  4.3403e-03, -4.7708e-05,\n",
       "          9.4774e-04, -2.3490e-03,  6.1761e-03, -2.3459e-03, -2.7141e-03,\n",
       "          5.0079e-03,  2.9917e-03, -1.3224e-04, -4.9899e-03,  3.7369e-03,\n",
       "         -4.3257e-03, -9.6943e-04, -1.3769e-03,  1.4718e-03, -1.1774e-03,\n",
       "          1.9898e-03,  1.6162e-03,  1.9842e-03, -1.0242e-03, -2.5103e-03,\n",
       "          3.8040e-04, -2.3581e-03, -1.3877e-03,  3.2959e-03, -3.2832e-03,\n",
       "         -4.9646e-05,  1.5272e-03,  2.7060e-03, -5.3892e-04, -1.7320e-05,\n",
       "          8.8892e-05, -3.9011e-03,  1.6642e-04, -2.3966e-03, -8.1226e-04,\n",
       "         -2.9875e-03,  4.5100e-03,  1.2847e-03,  1.5020e-03,  1.3109e-03,\n",
       "          3.7009e-03,  1.0019e-03,  1.3826e-03,  1.4400e-03,  2.1941e-03,\n",
       "         -1.6402e-03, -3.6665e-03, -1.0909e-04, -3.0021e-04, -4.5087e-04,\n",
       "         -6.2716e-05,  2.4222e-04, -7.3136e-05,  2.7222e-04,  1.0244e-04,\n",
       "         -1.1157e-04,  2.0240e-05,  3.9633e-04,  2.4952e-04, -2.3172e-04,\n",
       "         -4.9703e-04,  2.0433e-04, -7.7613e-04, -1.1396e-05,  2.0476e-04,\n",
       "          8.6149e-04, -1.9618e-04,  4.9280e-05, -7.5172e-05, -3.2694e-05,\n",
       "         -4.6390e-04, -4.3287e-05, -2.0254e-04, -2.6813e-04, -9.3772e-04,\n",
       "          1.9864e-04,  3.3830e-04, -1.6404e-04,  2.0949e-04, -2.2491e-04,\n",
       "          2.0077e-04, -2.0348e-04,  1.5902e-04, -6.1057e-04,  4.6627e-05,\n",
       "          1.4975e-04, -3.9675e-05, -3.2065e-04, -1.2347e-04, -5.2877e-05,\n",
       "         -2.9591e-04, -1.0278e-04, -1.8351e-05,  1.2279e-04, -5.4820e-05,\n",
       "         -1.8323e-03,  1.4336e-04,  5.5230e-04, -7.6677e-06,  3.1774e-04,\n",
       "         -4.0496e-05,  1.1737e-04,  8.8052e-04, -1.7388e-04,  4.1311e-04,\n",
       "          1.5164e-04, -8.8825e-05, -1.1965e-04,  8.5245e-04, -1.9150e-05,\n",
       "          3.8796e-04]),\n",
       " tensor([[ 6.7875e-05, -3.2821e-05,  3.0412e-05,  ..., -4.1184e-05,\n",
       "          -3.1660e-05, -1.0897e-05],\n",
       "         [ 2.6974e-05,  4.5234e-05,  2.3460e-05,  ..., -3.4351e-05,\n",
       "           1.6335e-05,  6.4040e-05],\n",
       "         [-1.1514e-04, -5.7141e-05, -4.5049e-07,  ...,  5.4015e-05,\n",
       "           2.0759e-05, -5.9658e-05],\n",
       "         ...,\n",
       "         [-3.7788e-05,  3.1951e-06,  1.7252e-05,  ..., -2.8934e-06,\n",
       "          -8.4386e-05,  1.1569e-05],\n",
       "         [-1.6328e-05, -8.9026e-06,  1.3128e-05,  ...,  1.7781e-07,\n",
       "          -6.7045e-06,  2.9280e-05],\n",
       "         [ 5.4785e-05,  1.2348e-04,  9.9187e-05,  ...,  4.5880e-05,\n",
       "          -4.1569e-05,  3.5891e-04]]),\n",
       " tensor([[ 2.6789e-05,  2.5817e-06,  1.7470e-05,  ..., -3.9485e-06,\n",
       "          -2.1686e-06,  4.9934e-05],\n",
       "         [-1.5155e-06,  8.2220e-06,  6.6637e-06,  ..., -9.2660e-06,\n",
       "           6.7952e-06,  1.4760e-05],\n",
       "         [-4.4180e-05, -3.6481e-06, -3.4525e-05,  ..., -3.2184e-06,\n",
       "          -1.4980e-05, -2.8476e-05],\n",
       "         ...,\n",
       "         [ 9.1828e-06,  1.6306e-05,  5.7115e-06,  ...,  4.4327e-05,\n",
       "          -1.3940e-06,  2.9086e-05],\n",
       "         [-3.7754e-06, -9.2701e-07, -5.3346e-06,  ..., -6.1439e-06,\n",
       "           9.5932e-07, -2.2224e-06],\n",
       "         [ 2.2037e-05,  7.1112e-06, -4.4027e-06,  ..., -3.3928e-06,\n",
       "           7.6356e-06,  1.0639e-04]]),\n",
       " tensor([-2.4685e-04, -7.8883e-05,  2.5402e-04,  1.9505e-04,  4.1909e-04,\n",
       "          1.2884e-05,  8.8951e-06,  5.3216e-05,  2.8299e-06, -5.3612e-05,\n",
       "          5.6748e-05, -2.9782e-04, -3.3765e-04, -5.6732e-04,  4.8493e-04,\n",
       "         -2.4177e-04,  1.2530e-04,  8.3346e-05, -2.5048e-04, -4.8965e-05,\n",
       "          1.7756e-04, -3.5959e-05, -1.9008e-04, -1.4940e-04, -1.2723e-04,\n",
       "         -1.1924e-05, -6.3912e-06, -2.0396e-04, -1.2076e-04,  2.2882e-04,\n",
       "          2.4543e-04, -3.2043e-05, -4.3644e-05,  8.0316e-05,  2.5699e-04,\n",
       "          2.2615e-04,  1.2091e-04, -2.9270e-04,  1.0507e-03,  1.0287e-04,\n",
       "          2.5726e-04, -3.5990e-04, -3.1045e-04, -1.5306e-04, -1.5113e-04,\n",
       "         -3.5552e-05,  6.6159e-04, -8.0991e-04, -1.3842e-04,  1.0586e-03,\n",
       "         -9.5656e-05, -7.3094e-06, -9.5925e-06,  4.5432e-05,  1.6196e-04,\n",
       "         -2.1151e-04, -4.8255e-05,  1.0739e-04,  4.0213e-04,  3.0305e-04,\n",
       "          4.9658e-04, -5.3389e-05,  1.4226e-05, -1.9061e-04, -3.1654e-04,\n",
       "         -6.7629e-05,  1.3933e-04, -3.7438e-05,  1.9136e-04,  2.9274e-05,\n",
       "          2.3915e-05,  1.1832e-05, -1.2400e-05, -6.7697e-05,  3.9962e-05,\n",
       "         -4.5466e-04, -1.7849e-04, -3.8763e-04,  3.6207e-04, -2.0430e-04,\n",
       "          7.2629e-05,  8.2827e-05, -2.6017e-04, -2.5571e-04,  2.1722e-04,\n",
       "          1.8773e-04,  4.7916e-05, -1.9807e-04, -1.0269e-04,  6.4659e-05,\n",
       "         -1.7673e-04, -2.1110e-04, -6.4240e-05,  1.7363e-04,  2.3635e-04,\n",
       "         -4.2114e-06, -7.2102e-05,  2.8303e-05,  3.4237e-04,  8.0129e-05,\n",
       "          1.9667e-04,  3.3551e-04,  9.5734e-04,  5.3518e-05,  6.7670e-04,\n",
       "         -3.6115e-04, -1.2761e-04, -1.8270e-05, -1.7619e-04, -4.4929e-04,\n",
       "          3.0124e-04, -5.2739e-04, -1.4519e-04,  1.2189e-03, -6.0426e-05,\n",
       "          6.0398e-05, -2.9525e-05, -3.1207e-04,  6.7772e-05, -8.1509e-05,\n",
       "         -3.9862e-05, -5.7873e-04,  5.0354e-04,  5.1555e-04,  7.2918e-04,\n",
       "          8.5131e-05,  3.0117e-05, -3.2499e-04,  2.1463e-03,  2.6692e-04,\n",
       "         -3.5559e-03, -2.3863e-03,  2.7409e-03, -5.8051e-06,  6.7003e-04,\n",
       "         -1.0315e-03,  4.5881e-04, -9.7527e-05,  1.7228e-03, -2.4896e-03,\n",
       "         -2.3556e-03,  2.1076e-03,  1.7421e-03, -4.2356e-03,  1.1339e-03,\n",
       "          4.9109e-04,  1.2088e-03, -3.5514e-03,  1.3618e-03, -2.5118e-03,\n",
       "         -1.0316e-03, -4.6714e-03, -7.0232e-04,  1.6378e-03,  2.1196e-03,\n",
       "          6.3503e-04,  1.7440e-03,  1.1823e-03,  2.2447e-03, -7.9275e-04,\n",
       "         -5.5318e-04, -1.6151e-03,  1.1648e-03,  1.6178e-03, -2.2955e-03,\n",
       "         -4.6709e-03,  4.4840e-03,  4.2470e-04,  4.2877e-03, -3.4263e-03,\n",
       "          2.8972e-03,  7.3203e-04,  1.1119e-03, -7.5188e-03,  4.3449e-03,\n",
       "         -6.6910e-03,  1.6302e-03, -3.9107e-03,  2.0092e-05, -3.5388e-04,\n",
       "         -5.4041e-04, -4.4377e-03, -6.9344e-04,  5.0198e-03, -2.3854e-03,\n",
       "         -1.0731e-02,  2.1075e-03, -2.2689e-03, -3.2983e-03,  2.6064e-03,\n",
       "         -1.0545e-04,  1.5056e-03, -2.7763e-04, -6.0265e-05,  2.1406e-04,\n",
       "          1.1126e-04,  3.1045e-04,  2.8844e-05,  1.8057e-05, -5.5303e-06,\n",
       "          6.2781e-06, -1.3515e-05,  4.8852e-05, -4.3284e-04, -4.4167e-04,\n",
       "         -5.3807e-04,  5.5604e-04, -2.1351e-04,  1.4139e-04,  5.4362e-05,\n",
       "         -3.7156e-04, -8.0050e-05,  1.8578e-04, -9.5285e-05, -3.0735e-04,\n",
       "         -9.1760e-05, -1.1382e-04, -7.0067e-05,  3.5518e-05, -3.9366e-04,\n",
       "         -1.6220e-04,  3.7142e-04,  2.5604e-04, -6.9179e-05, -5.9639e-05,\n",
       "         -6.2351e-06,  5.4678e-04,  2.3893e-04,  1.5720e-04, -2.8638e-04,\n",
       "          1.3954e-03,  8.3094e-05,  3.5596e-04, -5.2373e-04, -2.5620e-04,\n",
       "         -1.5247e-04, -1.4373e-04,  1.8103e-04,  6.9367e-04, -6.1442e-04,\n",
       "         -2.6030e-04,  1.4582e-03, -3.5571e-05, -1.8231e-05,  8.2034e-06,\n",
       "          1.1443e-05,  1.9154e-04, -2.3894e-04, -8.5517e-05,  2.4835e-04,\n",
       "          4.1761e-04,  3.0895e-04,  1.0557e-03, -1.0247e-04, -2.1795e-06,\n",
       "         -4.8761e-04]),\n",
       " tensor([-2.4685e-04, -7.8883e-05,  2.5402e-04,  1.9505e-04,  4.1909e-04,\n",
       "          1.2884e-05,  8.8951e-06,  5.3216e-05,  2.8299e-06, -5.3612e-05,\n",
       "          5.6748e-05, -2.9782e-04, -3.3765e-04, -5.6732e-04,  4.8493e-04,\n",
       "         -2.4177e-04,  1.2530e-04,  8.3346e-05, -2.5048e-04, -4.8965e-05,\n",
       "          1.7756e-04, -3.5959e-05, -1.9008e-04, -1.4940e-04, -1.2723e-04,\n",
       "         -1.1924e-05, -6.3912e-06, -2.0396e-04, -1.2076e-04,  2.2882e-04,\n",
       "          2.4543e-04, -3.2043e-05, -4.3644e-05,  8.0316e-05,  2.5699e-04,\n",
       "          2.2615e-04,  1.2091e-04, -2.9270e-04,  1.0507e-03,  1.0287e-04,\n",
       "          2.5726e-04, -3.5990e-04, -3.1045e-04, -1.5306e-04, -1.5113e-04,\n",
       "         -3.5552e-05,  6.6159e-04, -8.0991e-04, -1.3842e-04,  1.0586e-03,\n",
       "         -9.5656e-05, -7.3094e-06, -9.5925e-06,  4.5432e-05,  1.6196e-04,\n",
       "         -2.1151e-04, -4.8255e-05,  1.0739e-04,  4.0213e-04,  3.0305e-04,\n",
       "          4.9658e-04, -5.3389e-05,  1.4226e-05, -1.9061e-04, -3.1654e-04,\n",
       "         -6.7629e-05,  1.3933e-04, -3.7438e-05,  1.9136e-04,  2.9274e-05,\n",
       "          2.3915e-05,  1.1832e-05, -1.2400e-05, -6.7697e-05,  3.9962e-05,\n",
       "         -4.5466e-04, -1.7849e-04, -3.8763e-04,  3.6207e-04, -2.0430e-04,\n",
       "          7.2629e-05,  8.2827e-05, -2.6017e-04, -2.5571e-04,  2.1722e-04,\n",
       "          1.8773e-04,  4.7916e-05, -1.9807e-04, -1.0269e-04,  6.4659e-05,\n",
       "         -1.7673e-04, -2.1110e-04, -6.4240e-05,  1.7363e-04,  2.3635e-04,\n",
       "         -4.2114e-06, -7.2102e-05,  2.8303e-05,  3.4237e-04,  8.0129e-05,\n",
       "          1.9667e-04,  3.3551e-04,  9.5734e-04,  5.3518e-05,  6.7670e-04,\n",
       "         -3.6115e-04, -1.2761e-04, -1.8270e-05, -1.7619e-04, -4.4929e-04,\n",
       "          3.0124e-04, -5.2739e-04, -1.4519e-04,  1.2189e-03, -6.0426e-05,\n",
       "          6.0398e-05, -2.9525e-05, -3.1207e-04,  6.7772e-05, -8.1509e-05,\n",
       "         -3.9862e-05, -5.7873e-04,  5.0354e-04,  5.1555e-04,  7.2918e-04,\n",
       "          8.5131e-05,  3.0117e-05, -3.2499e-04,  2.1463e-03,  2.6692e-04,\n",
       "         -3.5559e-03, -2.3863e-03,  2.7409e-03, -5.8051e-06,  6.7003e-04,\n",
       "         -1.0315e-03,  4.5881e-04, -9.7527e-05,  1.7228e-03, -2.4896e-03,\n",
       "         -2.3556e-03,  2.1076e-03,  1.7421e-03, -4.2356e-03,  1.1339e-03,\n",
       "          4.9109e-04,  1.2088e-03, -3.5514e-03,  1.3618e-03, -2.5118e-03,\n",
       "         -1.0316e-03, -4.6714e-03, -7.0232e-04,  1.6378e-03,  2.1196e-03,\n",
       "          6.3503e-04,  1.7440e-03,  1.1823e-03,  2.2447e-03, -7.9275e-04,\n",
       "         -5.5318e-04, -1.6151e-03,  1.1648e-03,  1.6178e-03, -2.2955e-03,\n",
       "         -4.6709e-03,  4.4840e-03,  4.2470e-04,  4.2877e-03, -3.4263e-03,\n",
       "          2.8972e-03,  7.3203e-04,  1.1119e-03, -7.5188e-03,  4.3449e-03,\n",
       "         -6.6910e-03,  1.6302e-03, -3.9107e-03,  2.0092e-05, -3.5388e-04,\n",
       "         -5.4041e-04, -4.4377e-03, -6.9344e-04,  5.0198e-03, -2.3854e-03,\n",
       "         -1.0731e-02,  2.1075e-03, -2.2689e-03, -3.2983e-03,  2.6064e-03,\n",
       "         -1.0545e-04,  1.5056e-03, -2.7763e-04, -6.0265e-05,  2.1406e-04,\n",
       "          1.1126e-04,  3.1045e-04,  2.8844e-05,  1.8057e-05, -5.5303e-06,\n",
       "          6.2781e-06, -1.3515e-05,  4.8852e-05, -4.3284e-04, -4.4167e-04,\n",
       "         -5.3807e-04,  5.5604e-04, -2.1351e-04,  1.4139e-04,  5.4362e-05,\n",
       "         -3.7156e-04, -8.0050e-05,  1.8578e-04, -9.5285e-05, -3.0735e-04,\n",
       "         -9.1760e-05, -1.1382e-04, -7.0067e-05,  3.5518e-05, -3.9366e-04,\n",
       "         -1.6220e-04,  3.7142e-04,  2.5604e-04, -6.9179e-05, -5.9639e-05,\n",
       "         -6.2351e-06,  5.4678e-04,  2.3893e-04,  1.5720e-04, -2.8638e-04,\n",
       "          1.3954e-03,  8.3094e-05,  3.5596e-04, -5.2373e-04, -2.5620e-04,\n",
       "         -1.5247e-04, -1.4373e-04,  1.8103e-04,  6.9367e-04, -6.1442e-04,\n",
       "         -2.6030e-04,  1.4582e-03, -3.5571e-05, -1.8231e-05,  8.2034e-06,\n",
       "          1.1443e-05,  1.9154e-04, -2.3894e-04, -8.5517e-05,  2.4835e-04,\n",
       "          4.1761e-04,  3.0895e-04,  1.0557e-03, -1.0247e-04, -2.1795e-06,\n",
       "         -4.8761e-04])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.grad for x in list(model.encoder.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    cuda_device=0 if USE_GPU else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/03/2019 17:31:08 - INFO - allennlp.training.trainer -   Beginning training.\n",
      "02/03/2019 17:31:08 - INFO - allennlp.training.trainer -   Epoch 0/1\n",
      "02/03/2019 17:31:08 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 1845.4528\n",
      "02/03/2019 17:31:08 - INFO - allennlp.training.trainer -   Training\n",
      "loss: 0.6843 ||: 100%|██████████| 5/5 [00:27<00:00,  5.72s/it]\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   cpu_memory_MB |  1845.453  |       N/A\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   loss          |     0.684  |       N/A\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:27\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:27\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   Epoch 1/1\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 3073.642496\n",
      "02/03/2019 17:31:36 - INFO - allennlp.training.trainer -   Training\n",
      "loss: 0.6449 ||: 100%|██████████| 5/5 [00:23<00:00,  4.76s/it]\n",
      "02/03/2019 17:31:59 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "02/03/2019 17:31:59 - INFO - allennlp.training.trainer -   cpu_memory_MB |  3073.642  |       N/A\n",
      "02/03/2019 17:31:59 - INFO - allennlp.training.trainer -   loss          |     0.645  |       N/A\n",
      "02/03/2019 17:31:59 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:23\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
