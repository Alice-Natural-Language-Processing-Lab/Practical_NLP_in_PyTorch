{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import *\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.nn import util as nn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    testing=True,\n",
    "    seed=1,\n",
    "    batch_size=64,\n",
    "    lr=3e-4,\n",
    "    epochs=2,\n",
    "    hidden_sz=64,\n",
    "    max_seq_len=100, # necessary to limit memory usage\n",
    "    max_vocab_size=100000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.common.checks import ConfigurationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data\") / \"jigsaw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed manually to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ed476f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.dataset_readers import DatasetReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
    "              \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
    "\n",
    "class JigsawDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 max_seq_len: Optional[int]=config.max_seq_len) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[Token], id: str,\n",
    "                         labels: np.ndarray) -> Instance:\n",
    "        sentence_field = TextField(tokens, self.token_indexers)\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "        \n",
    "        id_field = MetadataField(id)\n",
    "        fields[\"id\"] = id_field\n",
    "        \n",
    "        label_field = ArrayField(array=labels)\n",
    "        fields[\"label\"] = label_field\n",
    "\n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        df = pd.read_csv(file_path)\n",
    "        if config.testing: df = df.head(1000)\n",
    "        for i, row in df.iterrows():\n",
    "            yield self.text_to_instance(\n",
    "                [Token(x) for x in self.tokenizer(row[\"comment_text\"])],\n",
    "                row[\"id\"], row[label_cols].values,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare token handlers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the spacy tokenizer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
    "\n",
    "# the token indexer is responsible for mapping tokens to integers\n",
    "token_indexer = ELMoTokenCharactersIndexer()\n",
    "\n",
    "def tokenizer(x: str):\n",
    "    return [w.text for w in\n",
    "            SpacyWordSplitter(language='en_core_web_sm', \n",
    "                              pos_tags=False).split_words(x)[:config.max_seq_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = JigsawDatasetReader(\n",
    "    tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [00:02, 128.71it/s]\n",
      "251it [00:01, 204.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = (reader.read(DATA_ROOT / fname) for fname in [\"train.csv\", \"test_proced.csv\"])\n",
    "val_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<allennlp.data.instance.Instance at 0x1a2b4931d0>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b476278>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b44c7b8>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b3f2898>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b3ea518>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b3e06a0>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b3dc780>,\n",
       " <allennlp.data.instance.Instance at 0x1a2b3c85c0>,\n",
       " <allennlp.data.instance.Instance at 0x10c1f6550>,\n",
       " <allennlp.data.instance.Instance at 0x1a291b93c8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [Explanation,\n",
       "  Why,\n",
       "  the,\n",
       "  edits,\n",
       "  made,\n",
       "  under,\n",
       "  my,\n",
       "  username,\n",
       "  Hardcore,\n",
       "  Metallica,\n",
       "  Fan,\n",
       "  were,\n",
       "  reverted,\n",
       "  ?,\n",
       "  They,\n",
       "  were,\n",
       "  n't,\n",
       "  vandalisms,\n",
       "  ,,\n",
       "  just,\n",
       "  closure,\n",
       "  on,\n",
       "  some,\n",
       "  GAs,\n",
       "  after,\n",
       "  I,\n",
       "  voted,\n",
       "  at,\n",
       "  New,\n",
       "  York,\n",
       "  Dolls,\n",
       "  FAC,\n",
       "  .,\n",
       "  And,\n",
       "  please,\n",
       "  do,\n",
       "  n't,\n",
       "  remove,\n",
       "  the,\n",
       "  template,\n",
       "  from,\n",
       "  the,\n",
       "  talk,\n",
       "  page,\n",
       "  since,\n",
       "  I,\n",
       "  'm,\n",
       "  retired,\n",
       "  now.89.205.38.27],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x1a27f67550>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_ds[0].fields[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/30/2019 14:32:16 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
      "100%|██████████| 267/267 [00:00<00:00, 67560.28it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_ds, max_vocab_size=config.max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterator is responsible for batching the data and preparing it for input into the model. We'll use the BucketIterator that batches text sequences of smilar lengths together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=config.batch_size, \n",
    "                          sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell the iterator how to numericalize the text data. We do this by passing the vocabulary to the iterator. This step is easy to forget so be careful! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': {'tokens': tensor([[[259,  74, 260,  ..., 261, 261, 261],\n",
       "           [259,  71,  74,  ..., 261, 261, 261],\n",
       "           [259,  74,  85,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  86,  79,  ..., 261, 261, 261],\n",
       "           [259,  78,  70,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  73, 112,  ..., 261, 261, 261],\n",
       "           [259, 100,  98,  ..., 261, 261, 261],\n",
       "           [259, 112, 111,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  50,  51,  ..., 261, 261, 261],\n",
       "           [259,  50,  57,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  35, 260,  ..., 261, 261, 261],\n",
       "           [259,  80, 113,  ..., 261, 261, 261],\n",
       "           [259, 227, 129,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259, 195, 163,  ..., 261, 261, 261],\n",
       "           [259,  35, 260,  ..., 261, 261, 261],\n",
       "           [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "  \n",
       "          [[259,  71,  98,  ..., 261, 261, 261],\n",
       "           [259,  99, 106,  ..., 261, 261, 261],\n",
       "           [259,  66, 116,  ..., 261, 261, 261],\n",
       "           ...,\n",
       "           [259,  41, 260,  ..., 261, 261, 261],\n",
       "           [259,  86,  85,  ..., 261, 261, 261],\n",
       "           [259,  42, 260,  ..., 261, 261, 261]]])},\n",
       " 'id': ['0084d905b6f19f2b',\n",
       "  '00637960a7ec3436',\n",
       "  '00397b264deba890',\n",
       "  '003f698d06c9b180',\n",
       "  '00229d44f41f3acb',\n",
       "  '0063f77040fbc7d4',\n",
       "  '006cf8c9f4cc4d57',\n",
       "  '0044cf18cc2655b3',\n",
       "  '00562e78e0b34102',\n",
       "  '0010833a96e1f886',\n",
       "  '00a1aabcab9d44a0',\n",
       "  '0009801bd85e5806',\n",
       "  '003910ffa2f50517',\n",
       "  '00a98913b0b8ba34',\n",
       "  '00803f08f55bdcad',\n",
       "  '008a990457283850',\n",
       "  '0011cc71398479c4',\n",
       "  '001c557175094f10',\n",
       "  '0071cd1ca07040ab',\n",
       "  '0035d638ba684122',\n",
       "  '007ecbb379c4a861',\n",
       "  '005ba6af463ab6cf',\n",
       "  '0034d7c78cfa6dee',\n",
       "  '000103f0d9cfb60f',\n",
       "  '00031b1e95af7921',\n",
       "  '003caacc6ce6c9e9',\n",
       "  '0060ef190ee10720',\n",
       "  '008e0818dde894fb',\n",
       "  '00604eb295a1dbf2',\n",
       "  '00290e2a171dd073',\n",
       "  '006493e4e9c89cab',\n",
       "  '000eefc67a2c930f',\n",
       "  '0048e4ed8a0af433',\n",
       "  '001dc38a83d420cf',\n",
       "  '00958dec64c33224',\n",
       "  '0053978373606ba4',\n",
       "  '006fc8cfaa4faf0b',\n",
       "  '00686325bcc16080',\n",
       "  '007094f2f9efe035',\n",
       "  '0050cb3bc226f94e',\n",
       "  '0097b052f0b68a96',\n",
       "  '00a216c00b90ce88',\n",
       "  '004fb9f655230909',\n",
       "  '004a23742282fee4',\n",
       "  '00169857adbc989b',\n",
       "  '004fd4fb5c47c29f',\n",
       "  '006b94add72ed61c',\n",
       "  '009371b0ef213487',\n",
       "  '0010307a3a50a353',\n",
       "  '009a52daa8dbb767',\n",
       "  '00316bcc0d1bc6e0',\n",
       "  '002918ae66cc4bc2',\n",
       "  '009a6b3e571ee155',\n",
       "  '006b77d41eb4bc08',\n",
       "  '0073059e6433db47',\n",
       "  '001e89eb3f0b0915',\n",
       "  '008a856f6691e051',\n",
       "  '00521847b93eba3b',\n",
       "  '00548d029d7f4783',\n",
       "  '0090c1f0788dd0e9',\n",
       "  '006fda507acd9769',\n",
       "  '0066dcf7d9ecd360',\n",
       "  '002a13f2896596fa',\n",
       "  '0095756047a71716'],\n",
       " 'label': tensor([[0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [1., 0., 1., 1., 1., 1.],\n",
       "         [1., 0., 1., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  74, 260,  ..., 261, 261, 261],\n",
       "         [259,  71,  74,  ..., 261, 261, 261],\n",
       "         [259,  74,  85,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  86,  79,  ..., 261, 261, 261],\n",
       "         [259,  78,  70,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  73, 112,  ..., 261, 261, 261],\n",
       "         [259, 100,  98,  ..., 261, 261, 261],\n",
       "         [259, 112, 111,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  50,  51,  ..., 261, 261, 261],\n",
       "         [259,  50,  57,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  35, 260,  ..., 261, 261, 261],\n",
       "         [259,  80, 113,  ..., 261, 261, 261],\n",
       "         [259, 227, 129,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 195, 163,  ..., 261, 261, 261],\n",
       "         [259,  35, 260,  ..., 261, 261, 261],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259,  71,  98,  ..., 261, 261, 261],\n",
       "         [259,  99, 106,  ..., 261, 261, 261],\n",
       "         [259,  66, 116,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259,  41, 260,  ..., 261, 261, 261],\n",
       "         [259,  86,  85,  ..., 261, 261, 261],\n",
       "         [259,  42, 260,  ..., 261, 261, 261]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 46, 50])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "\n",
    "class BaselineModel(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 out_sz: int=len(label_cols)):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
    "                id: Any, label: torch.Tensor) -> torch.Tensor:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        state = self.encoder(embeddings, mask)\n",
    "        class_logits = self.projection(state)\n",
    "        \n",
    "        output = {\"class_logits\": class_logits}\n",
    "        output[\"loss\"] = self.loss(class_logits, label)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/30/2019 14:32:17 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    }
   ],
   "source": [
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "\n",
    "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
    "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
    "\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
    "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how simple and modular the code for initializing the model is. All the complexity is delegated to each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda()\n",
    "else: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([[[259,  74, 260,  ..., 261, 261, 261],\n",
       "          [259,  71,  74,  ..., 261, 261, 261],\n",
       "          [259,  74,  85,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  86,  79,  ..., 261, 261, 261],\n",
       "          [259,  78,  70,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  73, 112,  ..., 261, 261, 261],\n",
       "          [259, 100,  98,  ..., 261, 261, 261],\n",
       "          [259, 112, 111,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  50,  51,  ..., 261, 261, 261],\n",
       "          [259,  50,  57,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  35, 260,  ..., 261, 261, 261],\n",
       "          [259,  80, 113,  ..., 261, 261, 261],\n",
       "          [259, 227, 129,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [259, 195, 163,  ..., 261, 261, 261],\n",
       "          [259,  35, 260,  ..., 261, 261, 261],\n",
       "          [  0,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "         [[259,  71,  98,  ..., 261, 261, 261],\n",
       "          [259,  99, 106,  ..., 261, 261, 261],\n",
       "          [259,  66, 116,  ..., 261, 261, 261],\n",
       "          ...,\n",
       "          [259,  41, 260,  ..., 261, 261, 261],\n",
       "          [259,  86,  85,  ..., 261, 261, 261],\n",
       "          [259,  42, 260,  ..., 261, 261, 261]]])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = get_text_field_mask(tokens)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2969e-02,  3.3753e-02,  1.2022e-01,  1.4575e-02,  2.2457e-01,\n",
       "         -2.0415e-01],\n",
       "        [-1.9613e-01, -1.7912e-02,  2.9364e-02,  1.1163e-01, -1.2791e-02,\n",
       "         -2.8244e-02],\n",
       "        [-1.0925e-01,  1.2709e-01,  7.7944e-02,  1.3847e-01,  7.8998e-03,\n",
       "         -2.1527e-01],\n",
       "        [-1.7458e-02, -1.0176e-02,  7.8199e-02, -1.0448e-01, -4.1375e-02,\n",
       "         -7.5978e-02],\n",
       "        [ 1.0936e-01, -8.1456e-03, -1.2194e-02,  1.8560e-02,  3.4497e-02,\n",
       "         -8.4653e-02],\n",
       "        [-5.1728e-02,  6.2288e-02, -1.2658e-02, -1.7544e-01,  1.1073e-01,\n",
       "         -9.4841e-02],\n",
       "        [ 1.1473e-02,  3.5975e-02,  1.0825e-01, -9.4212e-02,  1.3700e-01,\n",
       "         -1.3121e-01],\n",
       "        [-8.2636e-02, -3.1713e-02,  8.1382e-02,  3.3022e-02,  1.6678e-01,\n",
       "         -3.2406e-02],\n",
       "        [ 1.0901e-01,  1.0439e-01, -2.2460e-02, -9.4008e-02,  2.2116e-01,\n",
       "         -1.8600e-01],\n",
       "        [-1.5247e-01,  1.2574e-01,  2.6344e-01,  7.5079e-02,  8.9553e-02,\n",
       "         -8.4772e-02],\n",
       "        [-3.5631e-02, -1.0768e-02,  1.2991e-01, -6.0973e-02,  1.9337e-01,\n",
       "         -9.9148e-02],\n",
       "        [ 4.0546e-02, -4.6824e-02, -8.1185e-02,  1.3041e-01, -1.0296e-01,\n",
       "         -1.7716e-01],\n",
       "        [-9.9388e-02,  1.4074e-01,  1.1209e-01, -7.4724e-02, -3.5328e-02,\n",
       "         -2.2723e-01],\n",
       "        [-7.4153e-02, -1.3962e-01, -6.0457e-02, -3.7618e-02, -8.0397e-02,\n",
       "         -1.1261e-01],\n",
       "        [ 5.5757e-02,  2.2183e-01,  3.1653e-02,  1.7604e-02, -1.3172e-01,\n",
       "         -1.4141e-01],\n",
       "        [ 4.7751e-02, -6.7850e-02,  3.0976e-03,  1.4885e-01,  1.7931e-01,\n",
       "         -1.0746e-01],\n",
       "        [-6.6549e-02,  1.0557e-02,  4.6960e-02,  1.3008e-01,  1.2894e-01,\n",
       "         -1.1840e-01],\n",
       "        [-4.2517e-02,  1.5932e-01,  2.3367e-01,  4.2328e-02,  1.6079e-01,\n",
       "         -2.5199e-01],\n",
       "        [ 8.5667e-02,  1.2005e-04,  2.8842e-01,  1.2124e-01, -1.3173e-01,\n",
       "         -5.0638e-02],\n",
       "        [-6.3733e-02,  2.0352e-02, -1.1180e-01,  3.0781e-02,  2.0247e-01,\n",
       "         -6.1745e-02],\n",
       "        [ 8.9849e-02, -7.8680e-02,  1.6223e-01, -2.1025e-01,  4.7317e-02,\n",
       "         -1.0202e-01],\n",
       "        [-3.7112e-02, -5.0192e-02,  2.9110e-01, -1.6024e-02, -7.5038e-03,\n",
       "          4.6573e-02],\n",
       "        [ 8.1916e-02, -6.2872e-02, -3.6545e-02,  1.5242e-01,  1.7081e-01,\n",
       "          7.3248e-02],\n",
       "        [ 1.7203e-01, -1.3913e-01, -5.5547e-03, -1.5258e-01, -3.4222e-02,\n",
       "         -3.1022e-02],\n",
       "        [ 1.7185e-01,  1.2984e-02,  8.9154e-02,  3.9276e-02, -1.8885e-02,\n",
       "         -2.0989e-01],\n",
       "        [-5.0657e-02,  7.1654e-02,  1.8050e-01, -4.7684e-02,  5.8930e-02,\n",
       "         -1.1791e-01],\n",
       "        [-2.2941e-03, -1.2102e-01, -4.5316e-03, -3.6859e-02, -2.0931e-02,\n",
       "         -2.7427e-01],\n",
       "        [-2.3766e-01, -6.6892e-04,  9.9567e-02,  5.0797e-02,  7.3062e-02,\n",
       "         -1.1124e-01],\n",
       "        [-5.6769e-02, -1.4040e-02,  2.8911e-03, -1.8094e-02, -1.5082e-01,\n",
       "         -1.8560e-01],\n",
       "        [-5.8540e-02,  1.4147e-01,  9.7991e-02,  1.7378e-02, -3.7891e-02,\n",
       "         -6.3888e-02],\n",
       "        [-1.9410e-01, -4.7904e-02,  1.0983e-01, -1.4679e-01,  1.2518e-01,\n",
       "         -1.7918e-01],\n",
       "        [-5.2297e-02,  7.8957e-02, -6.8243e-03, -1.8310e-01,  4.7359e-02,\n",
       "         -1.7509e-02],\n",
       "        [ 5.4213e-02, -3.7991e-02,  1.3167e-01, -1.3404e-02,  6.6786e-02,\n",
       "         -2.6714e-01],\n",
       "        [-4.5073e-02,  7.5681e-02,  1.6269e-01,  8.4464e-02,  6.4936e-02,\n",
       "         -1.5991e-01],\n",
       "        [-1.1884e-01,  4.0670e-02, -2.7643e-02,  7.2370e-02,  1.5237e-02,\n",
       "         -2.3711e-02],\n",
       "        [ 1.7285e-02, -1.2404e-02,  5.8423e-02, -9.5116e-02, -7.5333e-02,\n",
       "          8.1458e-02],\n",
       "        [-6.3323e-02,  2.1491e-01,  1.7208e-01,  1.1579e-02,  2.0053e-01,\n",
       "         -1.1727e-01],\n",
       "        [-7.4932e-02,  5.8627e-02, -8.0371e-03, -2.8620e-02, -1.7154e-03,\n",
       "         -2.3972e-01],\n",
       "        [ 2.1354e-02,  3.8683e-02,  1.9372e-01,  5.9295e-02,  1.6594e-01,\n",
       "          2.3605e-02],\n",
       "        [ 5.3076e-02, -1.5279e-01,  9.4329e-02,  8.5845e-02,  2.6064e-01,\n",
       "         -1.0112e-01],\n",
       "        [-3.3436e-02,  5.8364e-02,  6.5485e-02, -2.2873e-02, -1.8369e-02,\n",
       "         -3.7428e-01],\n",
       "        [-1.4268e-01,  1.7188e-02, -1.4956e-01, -2.4148e-03,  1.2676e-01,\n",
       "         -7.5540e-02],\n",
       "        [-7.4789e-02,  2.0523e-02, -3.0174e-02, -3.2041e-02,  5.1518e-02,\n",
       "         -7.7716e-02],\n",
       "        [ 1.1551e-01,  1.6122e-01,  2.0545e-01, -4.6421e-02,  4.8846e-02,\n",
       "          6.9585e-03],\n",
       "        [ 5.0804e-02,  7.7466e-02,  1.5082e-01,  2.5297e-02,  1.9909e-01,\n",
       "         -5.7078e-02],\n",
       "        [ 2.1132e-01,  1.1261e-01,  1.5644e-01,  3.4846e-02, -1.4680e-01,\n",
       "         -6.0542e-02],\n",
       "        [-2.1026e-02,  5.7611e-02,  1.1388e-01,  1.1893e-02, -4.2110e-02,\n",
       "         -1.8185e-01],\n",
       "        [-3.3758e-02,  1.2996e-01,  4.0128e-02,  4.7196e-02, -2.7488e-02,\n",
       "         -9.5084e-02],\n",
       "        [-8.5972e-02,  1.5784e-02,  7.2446e-02, -5.3313e-02,  2.6690e-03,\n",
       "         -5.2810e-02],\n",
       "        [-1.1767e-01,  7.7763e-02,  1.7026e-01, -4.6952e-02,  9.1683e-02,\n",
       "          5.7168e-02],\n",
       "        [ 7.9619e-03,  2.3442e-02,  8.9518e-02,  4.3252e-02,  9.7180e-02,\n",
       "         -7.3877e-02],\n",
       "        [ 1.6257e-01,  5.4352e-02,  3.1007e-01,  7.6675e-02,  1.1431e-02,\n",
       "         -1.4809e-01],\n",
       "        [ 2.6382e-02,  3.9463e-02,  1.2296e-01, -1.4311e-01,  9.1509e-02,\n",
       "         -9.4697e-02],\n",
       "        [ 7.1920e-02,  4.2192e-03,  1.2500e-01,  3.8774e-03,  8.9673e-02,\n",
       "         -1.2114e-01],\n",
       "        [ 1.9184e-02, -1.3338e-02, -9.6843e-03,  1.6431e-01,  1.1903e-01,\n",
       "         -1.2020e-01],\n",
       "        [-5.5236e-04, -1.1005e-01,  3.7654e-02, -3.7799e-02,  7.9800e-02,\n",
       "         -9.8190e-02],\n",
       "        [-2.7311e-01, -7.6706e-02,  5.7464e-02,  9.5750e-02,  2.4850e-02,\n",
       "         -1.7051e-01],\n",
       "        [ 1.4733e-01,  4.2791e-02,  6.2775e-02, -1.0832e-01, -3.4831e-02,\n",
       "         -7.5472e-02],\n",
       "        [-1.4671e-02,  6.3854e-02,  8.7050e-02, -8.3199e-02, -4.8972e-02,\n",
       "         -2.2242e-02],\n",
       "        [ 2.6099e-02,  3.0566e-02,  1.9134e-01,  3.6920e-02,  5.5668e-02,\n",
       "         -2.1281e-01],\n",
       "        [-2.2396e-02,  1.0281e-01,  7.4047e-03,  1.4997e-02, -8.5464e-03,\n",
       "         -1.0871e-01],\n",
       "        [-1.3122e-01,  4.0173e-02,  1.1241e-01,  2.5594e-02, -4.0505e-02,\n",
       "         -7.6650e-02],\n",
       "        [-2.9232e-02,  7.5899e-02,  1.3764e-01, -1.3548e-01, -2.0086e-01,\n",
       "         -9.0451e-02],\n",
       "        [ 1.3864e-01,  5.7052e-02, -5.8499e-02,  9.9025e-02,  6.5170e-02,\n",
       "          7.5529e-02]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.word_embeddings(tokens)\n",
    "state = model.encoder(embeddings, mask)\n",
    "class_logits = model.projection(state)\n",
    "class_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_logits': tensor([[-3.1033e-02,  2.3331e-02,  1.2371e-01, -1.2836e-01,  1.4709e-01,\n",
       "          -1.7873e-01],\n",
       "         [-1.3789e-01,  2.4056e-02, -3.4560e-02, -6.0254e-02, -7.3038e-03,\n",
       "           2.7147e-03],\n",
       "         [-1.1190e-01, -6.4721e-02, -2.6389e-01,  2.0364e-01,  6.4780e-02,\n",
       "          -3.8040e-02],\n",
       "         [-3.3587e-02,  3.5838e-02,  4.4031e-02, -6.5696e-03, -2.8547e-02,\n",
       "          -1.2327e-01],\n",
       "         [ 3.7575e-02,  3.3898e-02,  8.6971e-02,  1.8634e-02, -2.6618e-02,\n",
       "          -1.6192e-01],\n",
       "         [-8.1112e-02,  9.8188e-02,  1.6625e-01, -2.1964e-01,  9.3888e-02,\n",
       "          -1.3452e-01],\n",
       "         [ 3.0536e-02, -2.4114e-02,  8.0818e-03, -8.3188e-02,  2.1043e-01,\n",
       "          -1.0255e-01],\n",
       "         [-1.8540e-02,  5.7744e-02, -7.2206e-04, -4.2356e-02,  1.9489e-01,\n",
       "          -1.4831e-01],\n",
       "         [-6.0753e-02,  1.3936e-02,  1.2929e-01,  5.3706e-02,  1.9803e-01,\n",
       "          -4.6742e-02],\n",
       "         [-1.2123e-01, -2.9820e-02,  1.8571e-01, -2.7066e-02,  6.7571e-02,\n",
       "          -1.8325e-01],\n",
       "         [-2.5905e-02,  1.0678e-01,  5.6697e-02, -8.0468e-02,  1.0891e-01,\n",
       "          -6.6234e-02],\n",
       "         [ 6.4530e-02, -7.2185e-03,  1.7265e-01,  2.1555e-01, -7.4646e-02,\n",
       "          -2.3127e-02],\n",
       "         [-8.6969e-02,  8.2462e-02,  1.6069e-02,  1.5325e-02, -6.0707e-02,\n",
       "          -7.9987e-02],\n",
       "         [-1.9021e-01, -2.5397e-01,  6.0772e-02,  3.4240e-02,  2.0090e-01,\n",
       "          -1.1791e-01],\n",
       "         [ 1.9515e-01,  8.0180e-02,  5.0533e-02, -1.1556e-01,  2.7404e-02,\n",
       "          -4.1087e-02],\n",
       "         [-8.3603e-02, -9.4725e-03,  4.7856e-02, -1.9333e-01,  1.6454e-01,\n",
       "          -2.7070e-02],\n",
       "         [-1.0030e-01,  7.0823e-02, -1.4056e-02,  1.6527e-02, -1.0780e-02,\n",
       "          -1.6276e-01],\n",
       "         [-6.3289e-02, -3.9698e-02,  7.4541e-02, -2.4967e-05,  1.1586e-01,\n",
       "          -2.0987e-01],\n",
       "         [ 1.5535e-01,  1.1079e-01,  1.6515e-01,  1.6363e-02,  3.6640e-02,\n",
       "          -2.4935e-02],\n",
       "         [-6.2336e-02, -9.6666e-02,  5.1947e-02,  3.0060e-02,  7.0197e-02,\n",
       "          -1.2650e-01],\n",
       "         [ 7.0841e-02,  1.0376e-01,  2.0578e-02,  1.8158e-02,  9.1866e-03,\n",
       "          -8.9093e-02],\n",
       "         [-4.4772e-03, -6.1945e-02,  9.3551e-02,  9.2200e-02,  1.3035e-01,\n",
       "           2.2942e-03],\n",
       "         [-7.9495e-03, -7.9133e-02,  1.7430e-01, -2.1139e-02, -2.0484e-02,\n",
       "          -8.6995e-03],\n",
       "         [-3.1751e-02, -1.0504e-01,  6.9592e-02, -7.5323e-02, -5.2688e-02,\n",
       "          -1.3142e-01],\n",
       "         [ 4.7057e-02, -3.6775e-02,  1.2862e-01, -3.4889e-02,  3.0750e-01,\n",
       "          -1.2324e-01],\n",
       "         [-1.6456e-01,  1.5114e-01,  6.7267e-02,  5.7844e-02,  3.8520e-03,\n",
       "          -2.8180e-01],\n",
       "         [-1.8504e-01,  1.7707e-02, -1.0335e-01,  2.2003e-02, -6.5259e-02,\n",
       "          -2.2511e-01],\n",
       "         [-1.7826e-01,  2.3850e-03, -1.0944e-02, -8.5148e-02,  8.5011e-02,\n",
       "          -5.2279e-02],\n",
       "         [ 6.0178e-03,  1.6137e-02,  7.6379e-02, -5.9364e-02,  3.0877e-02,\n",
       "          -1.1148e-01],\n",
       "         [-9.1998e-02,  7.0186e-02,  1.0896e-01, -7.8227e-02, -6.3506e-02,\n",
       "          -1.8054e-01],\n",
       "         [-4.4834e-02, -1.1155e-01, -1.2699e-01, -1.2683e-01,  1.7887e-01,\n",
       "          -8.4395e-02],\n",
       "         [-1.3460e-01,  2.3287e-01,  2.2434e-01,  5.1370e-02,  1.0115e-01,\n",
       "          -5.4997e-02],\n",
       "         [-9.6904e-03,  2.7820e-02,  5.1299e-02, -1.1641e-01,  8.0049e-02,\n",
       "          -2.5000e-01],\n",
       "         [ 2.3092e-02, -7.7037e-02,  1.7119e-02,  5.6417e-02,  4.1530e-02,\n",
       "          -8.7799e-02],\n",
       "         [ 5.5722e-03, -7.6100e-03,  8.0178e-02, -5.9123e-04, -8.1368e-02,\n",
       "          -3.2453e-02],\n",
       "         [ 7.4274e-02, -7.9316e-02,  8.0309e-03, -2.0791e-01,  1.4555e-01,\n",
       "          -3.3397e-02],\n",
       "         [-1.5715e-01,  5.2792e-02,  9.7706e-02,  1.4866e-01,  6.4611e-02,\n",
       "          -3.4533e-02],\n",
       "         [-7.9058e-03, -2.1732e-02, -5.4196e-02, -2.2316e-02,  9.8211e-02,\n",
       "          -1.1923e-01],\n",
       "         [-9.3199e-02,  3.8907e-02, -2.6470e-02, -1.1010e-02,  8.2700e-02,\n",
       "          -1.3189e-01],\n",
       "         [ 3.1619e-02, -2.4602e-01, -6.2848e-02,  8.1047e-03,  1.1959e-01,\n",
       "          -6.2051e-02],\n",
       "         [-1.4916e-01,  1.0708e-01,  2.7013e-02,  8.1753e-02,  1.4028e-01,\n",
       "          -2.6083e-01],\n",
       "         [ 8.5966e-02,  7.0445e-02, -1.1139e-02,  1.4057e-01,  3.5711e-02,\n",
       "          -8.0274e-03],\n",
       "         [ 3.3940e-02,  8.9538e-02,  9.7032e-02,  1.5523e-01,  3.0244e-02,\n",
       "          -2.5619e-01],\n",
       "         [ 9.9870e-02, -6.1904e-02,  1.6544e-01,  1.2205e-01,  1.4828e-01,\n",
       "          -6.4273e-02],\n",
       "         [-3.4144e-02,  4.6193e-03,  1.9925e-01, -2.6372e-03, -2.3224e-02,\n",
       "          -3.9742e-02],\n",
       "         [-1.4247e-01,  1.9748e-02,  1.5591e-02, -2.8177e-02,  1.0485e-01,\n",
       "          -2.8172e-02],\n",
       "         [ 1.7669e-01,  1.1500e-01,  1.6804e-01,  5.4630e-02,  1.8866e-02,\n",
       "          -1.8635e-01],\n",
       "         [-8.3903e-02, -8.6317e-02, -6.6143e-02,  1.3825e-01,  1.1324e-02,\n",
       "          -8.2353e-02],\n",
       "         [ 2.6169e-03,  4.9732e-03,  2.1068e-01,  2.7769e-03,  9.9775e-02,\n",
       "           6.8329e-03],\n",
       "         [-9.4949e-02, -8.8271e-02,  2.1781e-01, -7.7077e-02,  4.3122e-02,\n",
       "          -2.1198e-02],\n",
       "         [-8.9131e-02, -6.5514e-02,  5.4904e-02,  1.1491e-01,  6.4993e-02,\n",
       "           6.4890e-02],\n",
       "         [ 3.8170e-02, -1.9920e-02,  2.2252e-01, -4.4943e-02,  5.6632e-02,\n",
       "          -1.7006e-01],\n",
       "         [-1.1368e-02, -9.3744e-02,  2.2673e-01, -1.5545e-01,  1.1469e-01,\n",
       "          -6.2396e-02],\n",
       "         [ 9.9428e-02,  6.2185e-02,  2.1203e-01, -5.9893e-02, -4.0645e-02,\n",
       "          -2.1855e-01],\n",
       "         [-3.3268e-02,  4.6210e-02,  9.9802e-02,  8.0766e-02,  2.3039e-01,\n",
       "          -1.0626e-01],\n",
       "         [-1.4465e-01, -3.3431e-02,  2.6462e-02, -2.0289e-02,  5.3601e-02,\n",
       "          -3.0806e-01],\n",
       "         [-6.2503e-02,  4.9490e-02,  1.2649e-01,  3.8513e-02,  1.2103e-01,\n",
       "          -1.8082e-01],\n",
       "         [ 9.1357e-02,  5.4052e-02,  2.2307e-01, -5.1594e-02, -6.0886e-02,\n",
       "          -7.4453e-02],\n",
       "         [-9.0654e-03,  7.2256e-02,  1.0185e-01, -1.0882e-01,  1.0975e-01,\n",
       "          -1.6513e-01],\n",
       "         [ 1.2631e-01,  4.6401e-02,  1.7798e-01,  5.2196e-02, -2.1719e-01,\n",
       "          -2.3663e-01],\n",
       "         [-1.5207e-01,  1.0507e-01,  3.9403e-02,  1.0481e-02,  1.0280e-02,\n",
       "          -3.3753e-01],\n",
       "         [-1.9134e-01,  3.5441e-02,  2.0389e-02,  1.1009e-01,  1.9938e-01,\n",
       "          -1.0953e-01],\n",
       "         [-9.9323e-02,  2.6944e-02,  1.3055e-01, -2.4663e-02,  2.2369e-02,\n",
       "          -1.0670e-02],\n",
       "         [ 1.0870e-01,  1.4414e-01, -3.2903e-02,  8.3915e-02,  6.4742e-02,\n",
       "          -4.6783e-02]], grad_fn=<AddmmBackward>),\n",
       " 'loss': tensor(0.6951, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(**batch)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6979, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 2.1172e-06,  5.4381e-05,  5.5318e-06,  ..., -3.8330e-06,\n",
       "           5.6735e-05,  2.6381e-05],\n",
       "         [-1.0820e-04,  5.1226e-05, -3.8212e-05,  ..., -8.9566e-05,\n",
       "           1.4772e-04, -2.3325e-05],\n",
       "         [-1.9074e-04,  1.1211e-04,  1.4580e-05,  ...,  3.1020e-05,\n",
       "           2.5292e-04,  9.4283e-05],\n",
       "         ...,\n",
       "         [ 1.8176e-04, -9.9353e-05,  7.2918e-05,  ..., -3.9730e-05,\n",
       "          -2.6642e-04, -3.5973e-06],\n",
       "         [-3.0664e-05,  9.0954e-05,  6.9829e-05,  ..., -3.1430e-05,\n",
       "           5.4184e-05, -2.0345e-05],\n",
       "         [ 1.6058e-04, -8.0744e-05,  1.4813e-05,  ..., -1.0257e-04,\n",
       "          -2.5983e-04,  1.5409e-04]]),\n",
       " tensor([[-2.6208e-05, -2.2792e-07,  5.7287e-06,  ..., -2.4225e-05,\n",
       "           5.4475e-06,  1.3612e-05],\n",
       "         [-1.4566e-05,  1.1434e-05, -2.7109e-05,  ...,  5.0374e-05,\n",
       "          -1.8014e-06,  9.5703e-06],\n",
       "         [ 1.7004e-05,  2.4735e-05, -6.0654e-05,  ...,  1.4248e-05,\n",
       "          -1.1867e-05,  4.6304e-05],\n",
       "         ...,\n",
       "         [ 5.8953e-06, -5.4097e-07,  8.0115e-05,  ...,  1.2120e-04,\n",
       "           3.7830e-05, -4.3840e-05],\n",
       "         [-8.2136e-06,  2.1814e-07, -1.6011e-05,  ...,  6.3402e-06,\n",
       "          -3.1459e-05,  1.0292e-05],\n",
       "         [-1.9718e-06,  5.9785e-05,  1.1229e-04,  ..., -1.1668e-05,\n",
       "           1.5149e-05, -7.3728e-05]]),\n",
       " tensor([-1.7598e-05, -1.4886e-04, -4.2438e-04, -5.4138e-05,  2.7851e-04,\n",
       "         -3.6551e-05,  1.5180e-04,  1.1577e-04, -1.6869e-04, -6.1190e-05,\n",
       "          5.6558e-04,  5.8639e-04,  2.9389e-04, -3.0961e-04,  1.1081e-04,\n",
       "         -3.3487e-04,  1.7918e-05,  1.8443e-04,  5.7465e-04, -3.9591e-05,\n",
       "         -4.1735e-05, -6.4087e-05, -4.9998e-05, -3.3868e-04, -2.0937e-05,\n",
       "          2.2310e-05, -2.6580e-04, -7.8730e-04,  1.6824e-04,  3.3664e-04,\n",
       "         -2.8320e-04,  1.5238e-04, -1.5930e-04,  1.8857e-04,  2.1549e-05,\n",
       "          9.0988e-05, -4.7305e-04,  9.8914e-05,  1.3267e-04, -1.0433e-04,\n",
       "         -3.0408e-04, -6.8536e-05, -8.0108e-05, -2.0112e-04, -9.5125e-05,\n",
       "          5.6042e-05,  1.6237e-04, -4.4192e-05, -1.0912e-03,  6.3886e-05,\n",
       "          3.0483e-04, -2.6487e-05,  1.8732e-04,  3.3274e-05,  7.8315e-05,\n",
       "          4.6931e-04, -1.6591e-04,  3.5340e-04,  2.3079e-04, -1.0068e-05,\n",
       "         -1.5376e-04,  4.8485e-04,  9.3713e-06,  5.0347e-04, -1.4717e-04,\n",
       "          3.4243e-05, -2.9862e-04, -2.8890e-05,  5.0949e-04, -4.3534e-05,\n",
       "          1.7393e-04,  5.6842e-05,  1.7321e-04,  1.5666e-04,  3.6798e-04,\n",
       "          2.6712e-04, -5.0012e-05, -1.1529e-03,  3.6099e-04, -2.5949e-04,\n",
       "          5.7643e-05,  2.6891e-04,  5.7202e-04, -4.6585e-05,  6.1416e-05,\n",
       "          9.8756e-05,  1.8389e-04, -2.9280e-04,  7.5252e-06, -1.7097e-04,\n",
       "         -2.1958e-04, -3.0601e-04,  1.2143e-04,  1.1456e-04, -1.9134e-04,\n",
       "          1.3312e-04, -1.9583e-04,  2.7404e-04,  9.2915e-05,  4.6618e-05,\n",
       "         -4.9138e-04,  8.3640e-05,  3.5978e-04, -7.3506e-05, -5.1947e-04,\n",
       "         -6.4544e-05, -9.7878e-05, -2.2638e-04,  1.4472e-04,  7.2338e-05,\n",
       "          7.2976e-05,  4.3921e-05, -8.0457e-04,  1.4860e-05,  1.0686e-04,\n",
       "          9.5301e-07,  2.4708e-04, -6.4865e-05,  4.8144e-05,  6.5436e-04,\n",
       "         -6.5061e-05,  1.4040e-04,  1.9807e-04, -1.5123e-04, -8.3523e-06,\n",
       "          9.8610e-05,  3.3054e-05,  6.6579e-04,  3.9120e-03,  3.7279e-03,\n",
       "         -1.0582e-03,  2.8627e-04, -3.1444e-03,  3.1781e-03, -5.6064e-03,\n",
       "         -1.4248e-03,  5.0112e-03, -2.3606e-03, -3.6278e-03, -4.7269e-03,\n",
       "         -9.5540e-03, -3.8407e-03, -8.5003e-03,  4.1784e-03, -2.1763e-04,\n",
       "          1.1948e-03, -2.1913e-03,  5.2959e-03, -2.4218e-03, -3.0080e-03,\n",
       "          5.0836e-03,  3.2004e-03, -1.6145e-04, -4.7793e-03,  3.6563e-03,\n",
       "         -4.1072e-03, -9.6645e-04, -1.6184e-03,  1.2495e-03, -1.3495e-03,\n",
       "          1.9420e-03,  1.4741e-03,  2.2829e-03, -8.1797e-04, -2.3934e-03,\n",
       "          5.1415e-04, -2.0455e-03, -1.2175e-03,  3.4841e-03, -2.9195e-03,\n",
       "          2.0937e-04,  1.5251e-03,  2.6071e-03, -5.9971e-04, -3.5954e-05,\n",
       "          4.1308e-05, -3.2618e-03,  1.2170e-04, -2.4070e-03, -1.0786e-03,\n",
       "         -2.5956e-03,  5.1474e-03,  1.1020e-03,  1.7614e-03,  1.5618e-03,\n",
       "          3.5750e-03,  1.0997e-03,  1.5168e-03,  1.4027e-03,  2.5574e-03,\n",
       "         -1.8353e-03, -4.2888e-03, -1.8557e-05, -2.6701e-04, -4.5470e-04,\n",
       "         -4.2944e-05,  3.5050e-04,  3.7003e-05,  3.0760e-04,  1.5301e-04,\n",
       "         -2.4799e-04, -1.0652e-04,  4.6952e-04,  3.9851e-04, -8.5090e-05,\n",
       "         -4.0931e-04,  3.3155e-04, -5.7114e-04,  1.5472e-05,  1.5190e-04,\n",
       "          7.9862e-04, -9.2746e-05, -9.9002e-05, -6.5788e-05, -1.9584e-04,\n",
       "         -4.3551e-04, -1.9815e-05, -2.5668e-05, -3.2568e-04, -9.4492e-04,\n",
       "          1.7331e-04,  3.1711e-04, -2.6207e-04,  1.5485e-04, -2.3798e-04,\n",
       "          2.2856e-04,  2.5388e-05,  1.3764e-04, -8.1259e-04,  1.0771e-04,\n",
       "          2.3148e-04, -1.0956e-04, -3.0123e-04, -7.6974e-05, -9.0536e-05,\n",
       "         -2.9799e-04, -1.8735e-04,  5.2443e-05,  1.3018e-04, -8.1496e-05,\n",
       "         -1.8763e-03,  8.9507e-05,  5.4332e-04, -5.1485e-05,  3.3618e-04,\n",
       "         -1.3236e-04,  9.4041e-05,  8.0814e-04, -1.4659e-04,  3.8664e-04,\n",
       "          1.9907e-04, -3.5642e-05, -1.4377e-04,  6.9014e-04, -5.1824e-05,\n",
       "          6.2538e-04]),\n",
       " tensor([-1.7598e-05, -1.4886e-04, -4.2438e-04, -5.4138e-05,  2.7851e-04,\n",
       "         -3.6551e-05,  1.5180e-04,  1.1577e-04, -1.6869e-04, -6.1190e-05,\n",
       "          5.6558e-04,  5.8639e-04,  2.9389e-04, -3.0961e-04,  1.1081e-04,\n",
       "         -3.3487e-04,  1.7918e-05,  1.8443e-04,  5.7465e-04, -3.9591e-05,\n",
       "         -4.1735e-05, -6.4087e-05, -4.9998e-05, -3.3868e-04, -2.0937e-05,\n",
       "          2.2310e-05, -2.6580e-04, -7.8730e-04,  1.6824e-04,  3.3664e-04,\n",
       "         -2.8320e-04,  1.5238e-04, -1.5930e-04,  1.8857e-04,  2.1549e-05,\n",
       "          9.0988e-05, -4.7305e-04,  9.8914e-05,  1.3267e-04, -1.0433e-04,\n",
       "         -3.0408e-04, -6.8536e-05, -8.0108e-05, -2.0112e-04, -9.5125e-05,\n",
       "          5.6042e-05,  1.6237e-04, -4.4192e-05, -1.0912e-03,  6.3886e-05,\n",
       "          3.0483e-04, -2.6487e-05,  1.8732e-04,  3.3274e-05,  7.8315e-05,\n",
       "          4.6931e-04, -1.6591e-04,  3.5340e-04,  2.3079e-04, -1.0068e-05,\n",
       "         -1.5376e-04,  4.8485e-04,  9.3713e-06,  5.0347e-04, -1.4717e-04,\n",
       "          3.4243e-05, -2.9862e-04, -2.8890e-05,  5.0949e-04, -4.3534e-05,\n",
       "          1.7393e-04,  5.6842e-05,  1.7321e-04,  1.5666e-04,  3.6798e-04,\n",
       "          2.6712e-04, -5.0012e-05, -1.1529e-03,  3.6099e-04, -2.5949e-04,\n",
       "          5.7643e-05,  2.6891e-04,  5.7202e-04, -4.6585e-05,  6.1416e-05,\n",
       "          9.8756e-05,  1.8389e-04, -2.9280e-04,  7.5252e-06, -1.7097e-04,\n",
       "         -2.1958e-04, -3.0601e-04,  1.2143e-04,  1.1456e-04, -1.9134e-04,\n",
       "          1.3312e-04, -1.9583e-04,  2.7404e-04,  9.2915e-05,  4.6618e-05,\n",
       "         -4.9138e-04,  8.3640e-05,  3.5978e-04, -7.3506e-05, -5.1947e-04,\n",
       "         -6.4544e-05, -9.7878e-05, -2.2638e-04,  1.4472e-04,  7.2338e-05,\n",
       "          7.2976e-05,  4.3921e-05, -8.0457e-04,  1.4860e-05,  1.0686e-04,\n",
       "          9.5301e-07,  2.4708e-04, -6.4865e-05,  4.8144e-05,  6.5436e-04,\n",
       "         -6.5061e-05,  1.4040e-04,  1.9807e-04, -1.5123e-04, -8.3523e-06,\n",
       "          9.8610e-05,  3.3054e-05,  6.6579e-04,  3.9120e-03,  3.7279e-03,\n",
       "         -1.0582e-03,  2.8627e-04, -3.1444e-03,  3.1781e-03, -5.6064e-03,\n",
       "         -1.4248e-03,  5.0112e-03, -2.3606e-03, -3.6278e-03, -4.7269e-03,\n",
       "         -9.5540e-03, -3.8407e-03, -8.5003e-03,  4.1784e-03, -2.1763e-04,\n",
       "          1.1948e-03, -2.1913e-03,  5.2959e-03, -2.4218e-03, -3.0080e-03,\n",
       "          5.0836e-03,  3.2004e-03, -1.6145e-04, -4.7793e-03,  3.6563e-03,\n",
       "         -4.1072e-03, -9.6645e-04, -1.6184e-03,  1.2495e-03, -1.3495e-03,\n",
       "          1.9420e-03,  1.4741e-03,  2.2829e-03, -8.1797e-04, -2.3934e-03,\n",
       "          5.1415e-04, -2.0455e-03, -1.2175e-03,  3.4841e-03, -2.9195e-03,\n",
       "          2.0937e-04,  1.5251e-03,  2.6071e-03, -5.9971e-04, -3.5954e-05,\n",
       "          4.1308e-05, -3.2618e-03,  1.2170e-04, -2.4070e-03, -1.0786e-03,\n",
       "         -2.5956e-03,  5.1474e-03,  1.1020e-03,  1.7614e-03,  1.5618e-03,\n",
       "          3.5750e-03,  1.0997e-03,  1.5168e-03,  1.4027e-03,  2.5574e-03,\n",
       "         -1.8353e-03, -4.2888e-03, -1.8557e-05, -2.6701e-04, -4.5470e-04,\n",
       "         -4.2944e-05,  3.5050e-04,  3.7003e-05,  3.0760e-04,  1.5301e-04,\n",
       "         -2.4799e-04, -1.0652e-04,  4.6952e-04,  3.9851e-04, -8.5090e-05,\n",
       "         -4.0931e-04,  3.3155e-04, -5.7114e-04,  1.5472e-05,  1.5190e-04,\n",
       "          7.9862e-04, -9.2746e-05, -9.9002e-05, -6.5788e-05, -1.9584e-04,\n",
       "         -4.3551e-04, -1.9815e-05, -2.5668e-05, -3.2568e-04, -9.4492e-04,\n",
       "          1.7331e-04,  3.1711e-04, -2.6207e-04,  1.5485e-04, -2.3798e-04,\n",
       "          2.2856e-04,  2.5388e-05,  1.3764e-04, -8.1259e-04,  1.0771e-04,\n",
       "          2.3148e-04, -1.0956e-04, -3.0123e-04, -7.6974e-05, -9.0536e-05,\n",
       "         -2.9799e-04, -1.8735e-04,  5.2443e-05,  1.3018e-04, -8.1496e-05,\n",
       "         -1.8763e-03,  8.9507e-05,  5.4332e-04, -5.1485e-05,  3.3618e-04,\n",
       "         -1.3236e-04,  9.4041e-05,  8.0814e-04, -1.4659e-04,  3.8664e-04,\n",
       "          1.9907e-04, -3.5642e-05, -1.4377e-04,  6.9014e-04, -5.1824e-05,\n",
       "          6.2538e-04]),\n",
       " tensor([[-9.3440e-06,  2.3473e-05,  2.5652e-05,  ..., -1.8497e-05,\n",
       "          -1.9612e-05,  2.2833e-05],\n",
       "         [ 3.3126e-06,  3.5032e-05,  2.4536e-05,  ..., -6.7515e-05,\n",
       "           2.1230e-06, -4.4868e-06],\n",
       "         [-3.1550e-05,  2.5119e-05,  6.0584e-05,  ...,  3.5822e-05,\n",
       "           6.2256e-05, -7.2001e-05],\n",
       "         ...,\n",
       "         [ 5.9599e-06,  9.9973e-05, -1.6186e-05,  ..., -6.8901e-05,\n",
       "          -2.2455e-05,  1.0480e-04],\n",
       "         [ 1.6718e-05, -1.0263e-06, -1.8706e-06,  ...,  1.0916e-05,\n",
       "           2.0589e-07, -2.1592e-06],\n",
       "         [ 8.9338e-05,  1.3919e-04,  5.8375e-05,  ..., -9.6169e-05,\n",
       "          -1.6353e-05,  3.1237e-04]]),\n",
       " tensor([[ 3.1586e-05,  7.8351e-06,  3.0379e-05,  ...,  2.2640e-05,\n",
       "          -1.3899e-05,  4.0512e-05],\n",
       "         [-4.6457e-06,  1.5509e-05,  7.5073e-06,  ...,  1.7696e-06,\n",
       "           5.6135e-06,  1.3860e-05],\n",
       "         [-1.0826e-05, -7.1633e-06,  4.4287e-06,  ..., -1.6019e-05,\n",
       "          -3.9383e-05, -1.9561e-05],\n",
       "         ...,\n",
       "         [ 3.8186e-05,  3.4050e-05,  1.1859e-05,  ...,  4.2602e-05,\n",
       "           5.3937e-06,  5.5928e-05],\n",
       "         [-1.2618e-06,  8.6472e-09,  7.9958e-06,  ..., -1.9468e-06,\n",
       "          -1.1548e-05,  7.7433e-06],\n",
       "         [ 3.6739e-05,  2.5753e-05, -1.9292e-05,  ...,  4.2645e-05,\n",
       "           1.9801e-05,  9.6822e-05]]),\n",
       " tensor([-2.4963e-04, -7.9265e-05,  4.4575e-05,  1.2417e-04,  3.3948e-04,\n",
       "         -3.1626e-06, -1.6446e-05, -2.6767e-05,  4.3720e-06, -2.0574e-05,\n",
       "          5.5211e-06, -3.5930e-04, -2.5773e-04, -6.0066e-04,  4.6462e-04,\n",
       "         -2.8769e-04,  1.0012e-04,  1.0742e-04, -2.6044e-04, -1.3039e-04,\n",
       "          1.9849e-04, -3.8583e-06, -1.5176e-04, -1.3311e-05, -5.9768e-05,\n",
       "         -9.0347e-05,  6.6680e-05, -2.4998e-04, -1.4335e-04,  2.6410e-04,\n",
       "          3.2264e-04, -6.1373e-05, -6.9803e-05,  1.7355e-04,  2.1155e-04,\n",
       "          2.1814e-04,  1.6239e-04, -8.8222e-05,  8.4321e-04,  1.0224e-04,\n",
       "          1.8780e-04, -5.6476e-04, -3.5957e-04, -1.7863e-04, -1.8875e-04,\n",
       "          4.2094e-04,  3.8490e-04, -5.6687e-04, -8.9269e-05,  9.8584e-04,\n",
       "         -3.2797e-05,  1.0733e-05, -4.1394e-05, -1.4032e-04,  1.6361e-04,\n",
       "         -3.1839e-04, -9.2665e-05, -1.4085e-04,  4.8674e-04,  3.3887e-04,\n",
       "          5.1088e-04, -3.1368e-04, -2.0508e-05, -2.4723e-04, -2.9588e-04,\n",
       "         -6.5687e-05,  4.9556e-05, -1.0649e-04,  1.4760e-04,  2.8916e-05,\n",
       "         -5.4207e-06, -4.6977e-05, -2.5835e-05,  4.0071e-05, -2.1702e-05,\n",
       "         -4.8856e-04, -2.2002e-04, -4.1619e-04,  3.6750e-04, -4.1990e-04,\n",
       "          6.8299e-05,  1.0060e-04, -2.4615e-04, -1.2794e-04,  2.1071e-04,\n",
       "          2.2645e-04, -1.5402e-06, -4.3376e-05, -1.2380e-04,  5.4367e-05,\n",
       "         -7.0593e-05, -2.4712e-04, -1.8975e-04,  1.9269e-04,  2.4279e-04,\n",
       "         -2.1686e-06, -5.8714e-05,  4.0943e-05,  3.3635e-04,  4.0356e-05,\n",
       "          2.1708e-04,  2.7597e-04,  1.2481e-03,  4.7611e-05,  5.7228e-04,\n",
       "         -5.2204e-04, -2.6096e-04, -1.4354e-05, -2.4019e-04,  2.2172e-05,\n",
       "          1.6064e-04, -4.8068e-04, -8.7824e-05,  1.0447e-03, -1.9061e-05,\n",
       "          3.1374e-05, -5.1638e-05, -5.2599e-04,  7.0803e-05, -1.3715e-04,\n",
       "          1.7380e-05, -5.5656e-04,  5.2425e-04,  4.9001e-04,  7.0946e-04,\n",
       "         -1.4410e-04, -1.8438e-05, -3.2948e-04,  2.0979e-03,  5.5084e-04,\n",
       "         -3.6589e-03, -2.9747e-03,  2.4383e-03, -1.2807e-05,  5.6695e-04,\n",
       "         -7.0973e-04,  4.7122e-04, -1.3532e-05,  1.5622e-03, -2.9195e-03,\n",
       "         -2.3668e-03,  2.1571e-03,  2.1818e-03, -4.3289e-03,  1.1890e-03,\n",
       "          5.6319e-04,  1.0619e-03, -3.6970e-03,  1.3706e-03, -2.7883e-03,\n",
       "         -7.8380e-04, -4.4311e-03, -8.6630e-04,  1.6476e-03,  1.9279e-03,\n",
       "          5.8105e-04,  2.1855e-03,  1.3380e-03,  1.9842e-03, -8.1019e-04,\n",
       "         -4.8915e-04, -1.6715e-03,  1.0639e-03,  1.7241e-03, -2.6319e-03,\n",
       "         -4.8277e-03,  4.6155e-03,  5.2845e-04,  4.1572e-03, -3.6386e-03,\n",
       "          2.8576e-03,  7.0537e-04,  1.0081e-03, -7.4916e-03,  4.7591e-03,\n",
       "         -6.8704e-03,  1.7298e-03, -3.5446e-03, -2.8085e-05, -4.4785e-04,\n",
       "         -3.9465e-04, -4.3553e-03, -6.6193e-04,  5.1401e-03, -2.7538e-03,\n",
       "         -9.9305e-03,  2.1240e-03, -1.9077e-03, -3.0180e-03,  2.5847e-03,\n",
       "         -2.1530e-04,  1.7657e-03, -3.0877e-04, -1.0587e-04, -6.1502e-05,\n",
       "          1.1003e-04,  2.2997e-04, -5.8363e-08,  4.0918e-05, -4.4605e-05,\n",
       "          6.8912e-06, -5.3610e-05,  2.0534e-05, -4.5420e-04, -3.2255e-04,\n",
       "         -5.1579e-04,  4.9510e-04, -1.8421e-04,  1.4853e-04,  8.0437e-05,\n",
       "         -4.0546e-04, -1.9507e-04,  1.7265e-04, -4.2163e-05, -2.4503e-04,\n",
       "         -1.1694e-04, -9.6308e-05, -5.2129e-05,  6.0608e-05, -4.1635e-04,\n",
       "         -1.9543e-04,  3.8340e-04,  3.2580e-04, -7.7334e-05, -1.0153e-04,\n",
       "          2.0363e-04,  4.4968e-04,  2.9583e-04,  2.1599e-04, -1.5999e-04,\n",
       "          1.4179e-03,  7.5665e-05,  2.0319e-04, -6.9253e-04, -2.6201e-04,\n",
       "         -1.6456e-04, -2.3985e-04,  8.5959e-04,  4.2937e-04, -6.8273e-04,\n",
       "         -3.5451e-04,  1.4495e-03, -2.2625e-05,  5.8705e-05, -5.9080e-05,\n",
       "         -1.6410e-04,  1.7536e-04, -3.9454e-04, -8.7786e-05, -2.2922e-04,\n",
       "          4.9493e-04,  3.9690e-04,  1.0679e-03, -3.4749e-04, -2.0288e-05,\n",
       "         -4.3404e-04]),\n",
       " tensor([-2.4963e-04, -7.9265e-05,  4.4575e-05,  1.2417e-04,  3.3948e-04,\n",
       "         -3.1626e-06, -1.6446e-05, -2.6767e-05,  4.3720e-06, -2.0574e-05,\n",
       "          5.5211e-06, -3.5930e-04, -2.5773e-04, -6.0066e-04,  4.6462e-04,\n",
       "         -2.8769e-04,  1.0012e-04,  1.0742e-04, -2.6044e-04, -1.3039e-04,\n",
       "          1.9849e-04, -3.8583e-06, -1.5176e-04, -1.3311e-05, -5.9768e-05,\n",
       "         -9.0347e-05,  6.6680e-05, -2.4998e-04, -1.4335e-04,  2.6410e-04,\n",
       "          3.2264e-04, -6.1373e-05, -6.9803e-05,  1.7355e-04,  2.1155e-04,\n",
       "          2.1814e-04,  1.6239e-04, -8.8222e-05,  8.4321e-04,  1.0224e-04,\n",
       "          1.8780e-04, -5.6476e-04, -3.5957e-04, -1.7863e-04, -1.8875e-04,\n",
       "          4.2094e-04,  3.8490e-04, -5.6687e-04, -8.9269e-05,  9.8584e-04,\n",
       "         -3.2797e-05,  1.0733e-05, -4.1394e-05, -1.4032e-04,  1.6361e-04,\n",
       "         -3.1839e-04, -9.2665e-05, -1.4085e-04,  4.8674e-04,  3.3887e-04,\n",
       "          5.1088e-04, -3.1368e-04, -2.0508e-05, -2.4723e-04, -2.9588e-04,\n",
       "         -6.5687e-05,  4.9556e-05, -1.0649e-04,  1.4760e-04,  2.8916e-05,\n",
       "         -5.4207e-06, -4.6977e-05, -2.5835e-05,  4.0071e-05, -2.1702e-05,\n",
       "         -4.8856e-04, -2.2002e-04, -4.1619e-04,  3.6750e-04, -4.1990e-04,\n",
       "          6.8299e-05,  1.0060e-04, -2.4615e-04, -1.2794e-04,  2.1071e-04,\n",
       "          2.2645e-04, -1.5402e-06, -4.3376e-05, -1.2380e-04,  5.4367e-05,\n",
       "         -7.0593e-05, -2.4712e-04, -1.8975e-04,  1.9269e-04,  2.4279e-04,\n",
       "         -2.1686e-06, -5.8714e-05,  4.0943e-05,  3.3635e-04,  4.0356e-05,\n",
       "          2.1708e-04,  2.7597e-04,  1.2481e-03,  4.7611e-05,  5.7228e-04,\n",
       "         -5.2204e-04, -2.6096e-04, -1.4354e-05, -2.4019e-04,  2.2172e-05,\n",
       "          1.6064e-04, -4.8068e-04, -8.7824e-05,  1.0447e-03, -1.9061e-05,\n",
       "          3.1374e-05, -5.1638e-05, -5.2599e-04,  7.0803e-05, -1.3715e-04,\n",
       "          1.7380e-05, -5.5656e-04,  5.2425e-04,  4.9001e-04,  7.0946e-04,\n",
       "         -1.4410e-04, -1.8438e-05, -3.2948e-04,  2.0979e-03,  5.5084e-04,\n",
       "         -3.6589e-03, -2.9747e-03,  2.4383e-03, -1.2807e-05,  5.6695e-04,\n",
       "         -7.0973e-04,  4.7122e-04, -1.3532e-05,  1.5622e-03, -2.9195e-03,\n",
       "         -2.3668e-03,  2.1571e-03,  2.1818e-03, -4.3289e-03,  1.1890e-03,\n",
       "          5.6319e-04,  1.0619e-03, -3.6970e-03,  1.3706e-03, -2.7883e-03,\n",
       "         -7.8380e-04, -4.4311e-03, -8.6630e-04,  1.6476e-03,  1.9279e-03,\n",
       "          5.8105e-04,  2.1855e-03,  1.3380e-03,  1.9842e-03, -8.1019e-04,\n",
       "         -4.8915e-04, -1.6715e-03,  1.0639e-03,  1.7241e-03, -2.6319e-03,\n",
       "         -4.8277e-03,  4.6155e-03,  5.2845e-04,  4.1572e-03, -3.6386e-03,\n",
       "          2.8576e-03,  7.0537e-04,  1.0081e-03, -7.4916e-03,  4.7591e-03,\n",
       "         -6.8704e-03,  1.7298e-03, -3.5446e-03, -2.8085e-05, -4.4785e-04,\n",
       "         -3.9465e-04, -4.3553e-03, -6.6193e-04,  5.1401e-03, -2.7538e-03,\n",
       "         -9.9305e-03,  2.1240e-03, -1.9077e-03, -3.0180e-03,  2.5847e-03,\n",
       "         -2.1530e-04,  1.7657e-03, -3.0877e-04, -1.0587e-04, -6.1502e-05,\n",
       "          1.1003e-04,  2.2997e-04, -5.8363e-08,  4.0918e-05, -4.4605e-05,\n",
       "          6.8912e-06, -5.3610e-05,  2.0534e-05, -4.5420e-04, -3.2255e-04,\n",
       "         -5.1579e-04,  4.9510e-04, -1.8421e-04,  1.4853e-04,  8.0437e-05,\n",
       "         -4.0546e-04, -1.9507e-04,  1.7265e-04, -4.2163e-05, -2.4503e-04,\n",
       "         -1.1694e-04, -9.6308e-05, -5.2129e-05,  6.0608e-05, -4.1635e-04,\n",
       "         -1.9543e-04,  3.8340e-04,  3.2580e-04, -7.7334e-05, -1.0153e-04,\n",
       "          2.0363e-04,  4.4968e-04,  2.9583e-04,  2.1599e-04, -1.5999e-04,\n",
       "          1.4179e-03,  7.5665e-05,  2.0319e-04, -6.9253e-04, -2.6201e-04,\n",
       "         -1.6456e-04, -2.3985e-04,  8.5959e-04,  4.2937e-04, -6.8273e-04,\n",
       "         -3.5451e-04,  1.4495e-03, -2.2625e-05,  5.8705e-05, -5.9080e-05,\n",
       "         -1.6410e-04,  1.7536e-04, -3.9454e-04, -8.7786e-05, -2.2922e-04,\n",
       "          4.9493e-04,  3.9690e-04,  1.0679e-03, -3.4749e-04, -2.0288e-05,\n",
       "         -4.3404e-04])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.grad for x in list(model.encoder.parameters())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    cuda_device=0 if USE_GPU else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/30/2019 14:32:43 - INFO - allennlp.training.trainer -   Beginning training.\n",
      "01/30/2019 14:32:43 - INFO - allennlp.training.trainer -   Epoch 0/1\n",
      "01/30/2019 14:32:43 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 1880.24832\n",
      "01/30/2019 14:32:43 - INFO - allennlp.training.trainer -   Training\n",
      "loss: 0.6841 ||: 100%|██████████| 5/5 [00:37<00:00,  6.60s/it]\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   loss          |     0.684  |       N/A\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   cpu_memory_MB |  1880.248  |       N/A\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:37\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:37\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   Epoch 1/1\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 3145.9328\n",
      "01/30/2019 14:33:21 - INFO - allennlp.training.trainer -   Training\n",
      "loss: 0.6510 ||: 100%|██████████| 5/5 [00:30<00:00,  6.19s/it]\n",
      "01/30/2019 14:33:51 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
      "01/30/2019 14:33:51 - INFO - allennlp.training.trainer -   loss          |     0.651  |       N/A\n",
      "01/30/2019 14:33:51 - INFO - allennlp.training.trainer -   cpu_memory_MB |  3145.933  |       N/A\n",
      "01/30/2019 14:33:51 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:30\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
